{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BRdPkqn04KqH"
      ],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewmlu/cs242-pa3/blob/main/CS242_Assignment_3_Andrew_Lu_Alex_Wilentz_Carl_Ho.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7ttBYeclcLI"
      },
      "source": [
        "# CS242: Assignment 3\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQGm6JtgehIq"
      },
      "source": [
        "> Harvard CS 242: Computing at Scale (Fall 2023)\n",
        "\n",
        ">\n",
        "> Instructor: Professor HT Kung\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRdPkqn04KqH"
      },
      "source": [
        "### **Assignment Instructions**\n",
        "\n",
        "**Please start this assignment early, especially those who are interested in doing a final project involving Federated Learning.**\n",
        "\n",
        "Read the following instructions carefully before starting the assignment and again before submitting your work:\n",
        "\n",
        "* This programming assignment must be completed with the same group you worked with in Assignment 2. **If you have any issues with this arrangement, please email Andrew immediately.**\n",
        "* We expect this assignment to take more time than Assignment 2. There is a more significant programming element involved, and more training time is required for the models. **Again, we suggest you start right away.**\n",
        "* The assignment consists of two parts: **this Google Colab file** (an .ipynb file) and a **LaTeX answer template**.\n",
        "* The Google Colab contains all assignment instructions and *Code Cells* that you will use to implement the programming components of the assignment in Python. **(Note: if there are any wording differences between the LaTeX template and this Colab file, the Colab file is authoritative and takes precedence.)**\n",
        "* We provide a significant amount of the code to make it easier to get started. In the *Code Cells*, please add comments to explain the purpose of each line of code in your implementation. **You will not receive credit for implementations that are not well-documented.**\n",
        "* <font color='red'>**Deliverables are highlighted in red**</font> in this Google Colab file. Use the LaTeX answer template to write down answers for these deliverables.\n",
        "* Each group will submit both a PDF of your answers and your Google Colab file (.ipynb file) containing all completed *Code cells* to \"Programming Assignment 3\" on Canvas. Only one submission per group. Check your .ipynb file using this [tool](https://htmtopdf.herokuapp.com/ipynbviewer/) before submitting to ensure that you completed all *Code Cells* (including detailed comments).\n",
        "* The assignment is due on **Wednesday, October 25, 2023 at 11:59 PM EST**.\n",
        "* Each part you are asked to implement is relatively small in isolation, and should be easy to test. We strongly recommend you test each of these parts before training the large models as to not waste time training models with buggy implementations. For example, you should ensure that your sampling is being done correctly, otherwise the model will still train, but your results will not be correct. For a number of sections, we have provided checks you can run to ensure correctness prior to training a large model.\n",
        "\n",
        "-----\n",
        "An outline of this assignment with point values and training estimates is given below. Note that these estimates represent a lower bound on the running time, assuming a correct implementation.\n",
        "\n",
        "1. **Exploring Federated Learning (FL)** [25 points] [Training Estimate: 2 hours]\n",
        "\n",
        "2. **Non-IID Federated Learning and Fairness** [30 points] [Training Estimate: 3 hours]\n",
        "\n",
        "3. **Quantization of Local Models for Reduced Communication Cost** [25 points] [Training Estimate: 3 hours]\n",
        "\n",
        "4. **Backdoor Attacks by Malicious Clients and Defenses** [15 points] [Training Estimate: 1.5 hours]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UvFA89jTuON"
      },
      "source": [
        "---\n",
        "\n",
        "### **1. Exploring Federated Learning (FL)**\n",
        "\n",
        "---\n",
        "We will be using a dataset (CIFAR-10) and CNN model (`ConvNet`) introduced in Programming Assignment 2. *Code Cell 1.1* creates the CIFAR-10 training and testing datasets. Additionally, it also contains the CNN (`ConvNet`)  that will be used throughout the assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9WL6HA_Lpe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59801a84-5971-466c-8a2b-eb41f3ba84e9"
      },
      "source": [
        "## Code Cell 1.1\n",
        "\n",
        "import time\n",
        "import copy\n",
        "import sys\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Using CIFAR-10 again as in Assignment 2\n",
        "# Load training data\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True,\n",
        "                                        transform=transform_train)\n",
        "\n",
        "# Load testing data\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True,\n",
        "                                       transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)\n",
        "\n",
        "\n",
        "# Using same ConvNet as in Assignment 2\n",
        "def conv_block(in_channels, out_channels, kernel_size=3, stride=1,\n",
        "               padding=1):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding,\n",
        "                  bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            conv_block(3, 32),\n",
        "            conv_block(32, 32),\n",
        "            conv_block(32, 64, stride=2),\n",
        "            conv_block(64, 64),\n",
        "            conv_block(64, 64),\n",
        "            conv_block(64, 128, stride=2),\n",
        "            conv_block(128, 128),\n",
        "            conv_block(128, 256),\n",
        "            conv_block(256, 256),\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "            )\n",
        "\n",
        "        self.classifier = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.model(x)\n",
        "        B, C, _, _ = h.shape\n",
        "        h = h.view(B, C)\n",
        "        return self.classifier(h)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 29515591.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjiB2IYp7B25"
      },
      "source": [
        "**Federated Learning Overview**\n",
        "\n",
        "Federated Learning (FL) distributes the task of training a deep neural network (such as our CNN `ConvNet`) across multiple client devices. Each client may have private data they do not want to share with a central server. Therefore, instead of transmitting data, clients perform training locally and send the updated model parameters (e.g., convolutional weights) to the server. The server averages these parameters across multiple clients to update the centralized model. Finally, after the centralized model has been updated, the server sends the new version of the model to all clients.\n",
        "\n",
        "The figure below depicts this Federated Learning paradigm (taken from [Towards Federated Learning at Scale: System Design](https://arxiv.org/pdf/1902.01046.pdf)). At the beginning of a training round in the selection phase, a percentage of devices (i.e., clients) agree to participate. By agreeing to participate, a client agrees to perform local training with its own dataset that resides on the device. During the configuration phase, the up-to-date centralized model is sent to the participating clients, which then perform local training. In the reporting phase, each client sends their own updated model (trained using local data) to the server for aggregation. Note that, in the figure, one of the clients fails to report back to the central server (either due to device or network failure). To simplify this assignment, we will assume this type of device/network failure is not possible.\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?id=1y8HAIxtNaZVLWetXHEzJ4UXWJ0yX_Jo0' />\n",
        "</figure>\n",
        "\n",
        "\n",
        "**Simulating Federated Learning**\n",
        "\n",
        "In this assignment, we will simulate this distributed Federated Learning environment on a single machine (i.e., a Colab instance). Each `device` will own a subset (or partition) of the dataset (e.g., 10% of the CIFAR-10 training set) and use it to train a local version of the model. The main difference between this simulated environment and a real system is the lack of networking between devices.\n",
        "\n",
        "You will use the `DatasetSplit` class in *Code Cell 1.2* to create subsets of the full training dataset. The `create_device` function creates a unique instance of `ConvNet`, an instance of the `DatasetSplit` dataloader, and an optimizer and scheduler for training. This function will be called multiple times (once per device) to create all the required device instances used for Federated Learning. The `train` and `test` functions are a modified version from Assignment 2 that take a device argument (the output from `create_device`. The batch size during training is set to 128 throughout the assignment. This is passed into the `create_device` function as a default parameter value (i.e., `batch_size=128`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSx1GxV2j0iI"
      },
      "source": [
        "## Code Cell 1.2\n",
        "import copy\n",
        "\n",
        "class DatasetSplit(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, idxs):\n",
        "        self.dataset = dataset\n",
        "        self.idxs = [int(i) for i in idxs]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idxs)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        image, label = self.dataset[self.idxs[item]]\n",
        "        return image, torch.tensor(label)\n",
        "\n",
        "def create_device(net, device_id, trainset, data_idxs, lr=0.1,\n",
        "                  milestones=None, batch_size=128):\n",
        "    if milestones == None:\n",
        "        milestones = [25, 50, 75]\n",
        "\n",
        "    device_net = copy.deepcopy(net)\n",
        "    optimizer = torch.optim.SGD(device_net.parameters(), lr=lr, momentum=0.9)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
        "                                                     milestones=milestones,\n",
        "                                                     gamma=0.1)\n",
        "    device_trainset = DatasetSplit(trainset, data_idxs)\n",
        "    device_trainloader = torch.utils.data.DataLoader(device_trainset,\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     shuffle=True)\n",
        "    return {\n",
        "        'net': device_net,\n",
        "        'id': device_id,\n",
        "        'dataloader': device_trainloader,\n",
        "        'optimizer': optimizer,\n",
        "        'scheduler': scheduler,\n",
        "        'train_loss_tracker': [],\n",
        "        'train_acc_tracker': [],\n",
        "        'test_loss_tracker': [],\n",
        "        'test_acc_tracker': [],\n",
        "        }\n",
        "\n",
        "def train(epoch, device):\n",
        "    net.train()\n",
        "    device['net'].train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(device['dataloader']):\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        device['optimizer'].zero_grad()\n",
        "        outputs = device['net'](inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        device['optimizer'].step()\n",
        "        train_loss += loss.item()\n",
        "        device['train_loss_tracker'].append(loss.item())\n",
        "        loss = train_loss / (batch_idx + 1)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        acc = 100. * correct / total\n",
        "        dev_id = device['id']\n",
        "        sys.stdout.write(f'\\r(Device {dev_id}/Epoch {epoch}) ' +\n",
        "                         f'Train Loss: {loss:.3f} | Train Acc: {acc:.3f}')\n",
        "        sys.stdout.flush()\n",
        "    device['train_acc_tracker'].append(acc)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def test(epoch, device):\n",
        "    net.eval()\n",
        "    test_loss, correct, total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = device['net'](inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "            device['test_loss_tracker'].append(loss.item())\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            loss = test_loss / (batch_idx + 1)\n",
        "            acc = 100.* correct / total\n",
        "    sys.stdout.write(f' | Test Loss: {loss:.3f} | Test Acc: {acc:.3f}\\n')\n",
        "    sys.stdout.flush()\n",
        "    acc = 100.*correct/total\n",
        "    device['test_acc_tracker'].append(acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTEyxu91KNl-"
      },
      "source": [
        "**Single Device Scenario**\n",
        "\n",
        "Before implementing Federated Learning, we will train a model for a single client device using only local data without sending updates to a central server. By doing this, the device is only able to look at a small percentage of the CIFAR-10 training set (10% in this case), and should perform poorly.\n",
        "\n",
        "---\n",
        "<font color='red'>**PART 1.1:**</font> [5 points]\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 1.3*, implement the function `iid_sampler` to generate **IID** (independent and identically distributed) samples from the CIFAR-10 training set. We will use this function to generate training subsets for multiple devices in **PART 1.2**.\n",
        "2. In *Code Cell 1.4*, create a single device using the function `create_device`. This device should have 10% of the CIFAR-10 training set, obtained using `iid_sampler`.\n",
        "3. Train the model for 1000 epochs using the parameters specified in *Code Cell 1.4* (similar to Assignment 2). The number of epochs is 10x greater due to the single device having only 10% of the data. Plot the test accuracy (`device['test_acc_tracker']`) over the epochs and comment on the classification accuracy compared to using 100% of the dataset as in Assignment 2. (50 words maximum)\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-t76gDhjr-Z"
      },
      "source": [
        "## Code Cell 1.3\n",
        "import random\n",
        "def iid_sampler(dataset, num_devices, data_pct):\n",
        "    '''\n",
        "    dataset: PyTorch Dataset (e.g., CIFAR-10 training set)\n",
        "    num_devices: integer number of devices to create subsets for\n",
        "    data_pct: percentage of training samples to give each device\n",
        "              e.g., 0.1 represents 10%\n",
        "\n",
        "    return: a dictionary of the following format:\n",
        "      {\n",
        "        0: [3, 65, 2233, ..., 22] // device 0 sample indexes\n",
        "        1: [0, 2, 4, ..., 583] // device 1 sample indexes\n",
        "        ...\n",
        "      }\n",
        "\n",
        "    iid (independent and identically distributed) means that the indexes\n",
        "    should be drawn independently in a uniformly random fashion.\n",
        "    '''\n",
        "\n",
        "    # total number of samples in the dataset\n",
        "    total_samples = len(dataset)\n",
        "    num_samples = int(total_samples * data_pct)\n",
        "\n",
        "    # Part 1.1: Implement!\n",
        "    sampled = {}\n",
        "    for i in range(num_devices):\n",
        "      sampled[i] = random.sample(range(total_samples), num_samples)\n",
        "\n",
        "    return sampled\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifc4z-2Q8ab2"
      },
      "source": [
        "Now, perform training using a single device on a subset of the training dataset using your `iid_sampler`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLd3fFeS8VEN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "4077c6ad-04ac-41f9-a908-96dcb3c825d3"
      },
      "source": [
        "## Code Cell 1.4\n",
        "\n",
        "data_pct = 0.1\n",
        "epochs = 1000 # Part 1.1: Change to 1000 epochs\n",
        "num_devices = 1\n",
        "device_pct = 0.1\n",
        "net = ConvNet().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "milestones = [250, 500, 750]\n",
        "\n",
        "# Part 1.1: Implement the cifar iid_sampler to generate data_idxs for create_device\n",
        "data_idxs = iid_sampler(trainset, num_devices, data_pct)\n",
        "\n",
        "# Part 1.1: Create the device\n",
        "device = create_device(net, 'cuda0', trainset, data_idxs[0])  # debugged -- need to include 0 index, not even sure how it ran without it\n",
        "\n",
        "# Part 1.1: Train the device model for 100 epochs and plot the result\n",
        "# Standard Training Loop\n",
        "start_time = time.time()\n",
        "for epoch in range(epochs):\n",
        "    train(epoch, device)\n",
        "    # To speed up running time, only evaluate the test set every 10 epochs\n",
        "    if epoch > 0 and epoch % 10 == 0:\n",
        "        test(epoch, device)\n",
        "    device['scheduler'].step()\n",
        "\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print('Total training time: {} seconds'.format(total_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Device cuda0/Epoch 0) Train Loss: 2.030 | Train Acc: 23.661"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-4cd8d6721cc0>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;31m# To speed up running time, only evaluate the test set every 10 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-08612fc5ed15>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, device)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mdevice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'net'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataloader'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-08612fc5ed15>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3101\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   3025\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3027\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombytes\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2966\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2968\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2969\u001b[0m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   2930\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImagePalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImagePalette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2931\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2932\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4waD2ZlQI4X2"
      },
      "source": [
        "**Implementing Components for Federated Learning**\n",
        "\n",
        "In **PART 1.1**, you implemented `iid_sampler`, created a 10% subset of the CIFAR-10 training set, and used it to train a single client device model. Since the client only had a 10% subset of the full CIFAR-10 training set, it performed significantly worse than the same model trained on the entire training set.\n",
        "\n",
        "Federated Learning aims to improve the performance of these client devices by averaging the updates from multiple clients over the course of training. This way, a centralized server is able to be updated using the training data stored on local devices without having access to the training data.\n",
        "By using more client devices, you will be able to leverage the entire dataset.\n",
        "In a way, this simulates traditional gradient descent, but with additional epochs performed on each client before averaging, where each epoch uses mini-batches of size 128.\n",
        "An additional benefit of federated learning is that the centralized server does not require large compute resources, as most of the training computation is performed on local devices.\n",
        "This makes the training computation \"free\" for the centralized server, as the clients pay the compute cost on their local devices.\n",
        "\n",
        "---\n",
        "<font color='red'>**PART 1.2:**</font> [10 points]\n",
        "\n",
        "Before implementing Federated Learning, you must implement two functions which will be used during the training process.\n",
        "\n",
        "The `average_weights` function takes in multiple device models, and computes the average for each model parameter across all models. This function will be called by the centralized server to aggregate the training performed by the end user devices. This averaging is done in 32-bit floating point (`float32`).\n",
        "\n",
        "The `get_devices_for_round` function will be used to simulate the device rejection phase shown earlier in the figure in the **Federated Learning Overview** section. This function will select a percentage of devices to participate in each training round.\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 1.5*, implement `average_weights`. We have provided test code you can use to validate your implementation. This test code will also be useful for the full implementation of Federated Learning in **PART 1.3**.\n",
        "2. In *Code Cell 1.5*, implement the `get_devices_for_round` function. Try multiple `device_pct` settings to ensure that it is working properly.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X0fTWKg6hBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0053cb0c-cf43-4c1c-f1e8-30265e4d1de8"
      },
      "source": [
        "## Code Cell 1.5\n",
        "import copy\n",
        "\n",
        "\n",
        "def average_weights(devices):\n",
        "    '''\n",
        "    devices: a list of devices generated by create_devices\n",
        "    Returns an the average of the weights.\n",
        "    '''\n",
        "    # Part 1.2: Implement!\n",
        "    # Hint: device['net'].state_dict() will return an OrderedDict of all\n",
        "    #       tensors in the model. Return the average of each tensor using\n",
        "    #       and OrderedDict so that you can update the global model using\n",
        "    #       device['net'].load_state_dict(w_avg), where w_avg is the\n",
        "    #       averaged OrderedDict over all devices\n",
        "    num_devices = len(devices)\n",
        "    state_dict = copy.deepcopy(devices[0]['net'].state_dict())\n",
        "    layers_list = list(state_dict.keys())\n",
        "    for i, device in enumerate(devices):\n",
        "      if i != 0:\n",
        "        for layer in layers_list[:4]:  # debugged -- only first 4 items are layers\n",
        "          state_dict[layer] += copy.deepcopy(device['net'].state_dict())[layer]\n",
        "          if i == num_devices - 1:\n",
        "            # print(layer)\n",
        "            # print(state_dict[layer])\n",
        "            state_dict[layer] /= num_devices  # debugged: need to divide by number of devices to average\n",
        "    return state_dict\n",
        "\n",
        "\n",
        "def get_devices_for_round(devices, device_pct):\n",
        "    '''\n",
        "    '''\n",
        "    # Part 1.2: Implement!\n",
        "    num_devices = len(devices)\n",
        "    device_idxs = random.sample(range(num_devices), int(num_devices * device_pct))\n",
        "    return [devices[i] for i in device_idxs]  # debugged -- need to return devices not just indices like above\n",
        "\n",
        "\n",
        "# Test code for average_weights\n",
        "# Hint: This test may be useful for Part 1.3!\n",
        "class TestNetwork(nn.Module):\n",
        "    '''\n",
        "    A simple 2 layer MLP used for testing your average_weights implementation.\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(TestNetwork, self).__init__()\n",
        "        self.layer1 = nn.Linear(2, 2)\n",
        "        self.layer2 = nn.Linear(2, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.layer1(x))\n",
        "        return self.layer2(h)\n",
        "\n",
        "data_pct = 0.05\n",
        "num_devices = 2\n",
        "net = TestNetwork()\n",
        "data_idxs = iid_sampler(trainset, num_devices, data_pct)\n",
        "devices = [create_device(net, i, trainset, data_idxs[i])\n",
        "           for i in range(num_devices)]\n",
        "\n",
        "# Fixed seeding to compare against precomputed correct_weight_averages below\n",
        "torch.manual_seed(0)\n",
        "devices[0]['net'].layer1.weight.data.normal_()\n",
        "devices[0]['net'].layer1.bias.data.normal_()\n",
        "devices[0]['net'].layer2.weight.data.normal_()\n",
        "devices[0]['net'].layer2.bias.data.normal_()\n",
        "devices[1]['net'].layer1.weight.data.normal_()\n",
        "devices[1]['net'].layer1.bias.data.normal_()\n",
        "devices[1]['net'].layer2.weight.data.normal_()\n",
        "devices[1]['net'].layer2.bias.data.normal_()\n",
        "\n",
        "# Precomputed correct averages\n",
        "correct_weight_averages = OrderedDict(\n",
        "    [('layer1.weight', torch.tensor([[ 0.3245, -0.9013], [-0.9042,  1.0125]])),\n",
        "     ('layer1.bias', torch.tensor([-0.0724, -0.3119])),\n",
        "     ('layer2.weight', torch.tensor([[0.2976,  1.0509], [-1.0048, -0.5972],\n",
        "                                     [-0.3088, -0.2682], [-0.1690, -0.1060]])),\n",
        "     ('layer2.bias', torch.tensor([-0.4396,  0.3327, -1.3925,  0.3160]))\n",
        "    ])\n",
        "\n",
        "# Computed weight averages\n",
        "computed_weight_averages = average_weights(devices)\n",
        "# print(computed_weight_averages)\n",
        "\n",
        "mismatch_found = False\n",
        "for correct, computed in zip(correct_weight_averages.items(),\n",
        "                             computed_weight_averages.items()):\n",
        "    if not torch.allclose(correct[1], computed[1], atol=1e-2):\n",
        "        mismatch_found = True\n",
        "        print('Mismatch in tensor:', correct[0])\n",
        "\n",
        "if not mismatch_found:\n",
        "    print('Implementation output matches!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Implementation output matches!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgzNJfpM4kUj"
      },
      "source": [
        "**Federated Learning Training**\n",
        "\n",
        "---\n",
        "<font color='red'>**PART 1.3:**</font> [10 points]\n",
        "\n",
        "We will now run the federated learning in the IID setting using the functions you previously wrote in this section.\n",
        "The parameters are given to you in the code.\n",
        "You will use 100 rounds of federated learning updates.\n",
        "For each round, each device that participates in a given round will complete 4 epochs of local training.\n",
        "10% of devices should participate in each round, selected by the `get_devices_for_round` function you wrote previously.\n",
        "Note that we use static initialization for the models between all parts of the assignment.\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 1.6*, train a global model via federated learning.\n",
        "Much of the code has been given to you, but you will need to fill in the parts using calls to the functions you wrote above.\n",
        "\n",
        "2. Graph the accuracy of the global model over 100 rounds.\n",
        "Discuss the accuracy difference between the global model trained here and the individual local model you trained in **PART 1.1**. (50 words maximum)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8OZxTJK4m8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed2b6ea-3236-49f3-aa7b-2b4880d1b3ec"
      },
      "source": [
        "## Code Cell 1.6\n",
        "\n",
        "# use these parameters\n",
        "rounds = 100 # Part 1.3: Change to 100 epochs\n",
        "local_epochs = 4\n",
        "num_devices = 50\n",
        "device_pct = 0.1\n",
        "data_pct = 0.1\n",
        "net = ConvNet().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "data_idxs = iid_sampler(trainset, num_devices, data_pct)\n",
        "\n",
        "# Part 1.3: Implement device creation here\n",
        "devices = [create_device(net, 'cuda' + str(i), trainset, data_idxs[i]) for i in range(num_devices)]\n",
        "# print(len(devices))\n",
        "# print(devices[0]['net'])\n",
        "# round_devices = get_devices_for_round(devices, data_pct)\n",
        "\n",
        "## IID Federated Learning\n",
        "start_time = time.time()\n",
        "for round_num in range(rounds):\n",
        "    # Part 1.3: Implement getting devices for each round here\n",
        "\n",
        "    round_devices = get_devices_for_round(devices, data_pct)\n",
        "    # print('Round: ', round_num)\n",
        "    # print(len(round_devices))\n",
        "    # print(round_devices)\n",
        "    for device in round_devices:\n",
        "        # print(device)\n",
        "        for local_epoch in range(local_epochs):\n",
        "            train(local_epoch, device)\n",
        "\n",
        "    # Weight averaging\n",
        "    w_avg = average_weights(round_devices)\n",
        "\n",
        "    for device in devices:\n",
        "        device['net'].load_state_dict(w_avg)\n",
        "        device['optimizer'].zero_grad()\n",
        "        device['optimizer'].step()\n",
        "        device['scheduler'].step()\n",
        "\n",
        "    # test accuracy after aggregation\n",
        "    test(round_num, devices[0])\n",
        "\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print('Total training time: {} seconds'.format(total_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Device cuda29/Epoch 3) Train Loss: 1.683 | Train Acc: 37.980 | Test Loss: 1.797 | Test Acc: 31.060\n",
            "(Device cuda8/Epoch 3) Train Loss: 1.629 | Train Acc: 39.700 | Test Loss: 1.722 | Test Acc: 35.520\n",
            "(Device cuda46/Epoch 3) Train Loss: 1.433 | Train Acc: 46.980 | Test Loss: 1.532 | Test Acc: 42.460\n",
            "(Device cuda10/Epoch 3) Train Loss: 1.304 | Train Acc: 51.680 | Test Loss: 1.432 | Test Acc: 49.350\n",
            "(Device cuda43/Epoch 3) Train Loss: 1.201 | Train Acc: 57.140 | Test Loss: 1.354 | Test Acc: 52.590\n",
            "(Device cuda21/Epoch 3) Train Loss: 1.119 | Train Acc: 59.900 | Test Loss: 1.210 | Test Acc: 56.380\n",
            "(Device cuda30/Epoch 3) Train Loss: 1.046 | Train Acc: 63.560 | Test Loss: 1.150 | Test Acc: 59.080\n",
            "(Device cuda37/Epoch 3) Train Loss: 0.906 | Train Acc: 67.000 | Test Loss: 1.079 | Test Acc: 62.320\n",
            "(Device cuda29/Epoch 3) Train Loss: 0.874 | Train Acc: 68.600 | Test Loss: 0.999 | Test Acc: 65.430\n",
            "(Device cuda45/Epoch 3) Train Loss: 0.856 | Train Acc: 70.120 | Test Loss: 1.015 | Test Acc: 65.590\n",
            "(Device cuda14/Epoch 3) Train Loss: 0.749 | Train Acc: 73.280 | Test Loss: 0.895 | Test Acc: 69.190\n",
            "(Device cuda10/Epoch 3) Train Loss: 0.709 | Train Acc: 75.080 | Test Loss: 0.886 | Test Acc: 69.650\n",
            "(Device cuda3/Epoch 3) Train Loss: 0.681 | Train Acc: 76.320 | Test Loss: 0.949 | Test Acc: 68.200\n",
            "(Device cuda35/Epoch 3) Train Loss: 0.674 | Train Acc: 76.720 | Test Loss: 0.893 | Test Acc: 69.640\n",
            "(Device cuda40/Epoch 3) Train Loss: 0.586 | Train Acc: 79.860 | Test Loss: 0.822 | Test Acc: 72.460\n",
            "(Device cuda2/Epoch 3) Train Loss: 0.603 | Train Acc: 79.460 | Test Loss: 0.749 | Test Acc: 74.890\n",
            "(Device cuda22/Epoch 3) Train Loss: 0.531 | Train Acc: 81.700 | Test Loss: 0.815 | Test Acc: 73.190\n",
            "(Device cuda49/Epoch 3) Train Loss: 0.540 | Train Acc: 81.540 | Test Loss: 0.789 | Test Acc: 73.780\n",
            "(Device cuda6/Epoch 3) Train Loss: 0.564 | Train Acc: 79.780 | Test Loss: 0.816 | Test Acc: 73.510\n",
            "(Device cuda23/Epoch 3) Train Loss: 0.497 | Train Acc: 83.000 | Test Loss: 0.791 | Test Acc: 74.210\n",
            "(Device cuda3/Epoch 3) Train Loss: 0.471 | Train Acc: 84.160 | Test Loss: 0.676 | Test Acc: 77.310\n",
            "(Device cuda9/Epoch 3) Train Loss: 0.508 | Train Acc: 82.240 | Test Loss: 0.705 | Test Acc: 76.640\n",
            "(Device cuda17/Epoch 3) Train Loss: 0.484 | Train Acc: 82.800 | Test Loss: 0.674 | Test Acc: 77.610\n",
            "(Device cuda7/Epoch 3) Train Loss: 0.419 | Train Acc: 85.220 | Test Loss: 0.682 | Test Acc: 77.260\n",
            "(Device cuda0/Epoch 3) Train Loss: 0.451 | Train Acc: 83.960 | Test Loss: 0.633 | Test Acc: 79.080\n",
            "(Device cuda16/Epoch 3) Train Loss: 0.410 | Train Acc: 86.300 | Test Loss: 0.612 | Test Acc: 79.860\n",
            "(Device cuda30/Epoch 3) Train Loss: 0.380 | Train Acc: 86.760 | Test Loss: 0.589 | Test Acc: 80.390\n",
            "(Device cuda46/Epoch 3) Train Loss: 0.316 | Train Acc: 89.320 | Test Loss: 0.585 | Test Acc: 80.530\n",
            "(Device cuda32/Epoch 3) Train Loss: 0.393 | Train Acc: 86.660 | Test Loss: 0.592 | Test Acc: 80.570\n",
            "(Device cuda12/Epoch 3) Train Loss: 0.399 | Train Acc: 87.120 | Test Loss: 0.580 | Test Acc: 80.900\n",
            "(Device cuda6/Epoch 3) Train Loss: 0.415 | Train Acc: 86.860 | Test Loss: 0.575 | Test Acc: 80.990\n",
            "(Device cuda45/Epoch 3) Train Loss: 0.340 | Train Acc: 88.440 | Test Loss: 0.587 | Test Acc: 80.800\n",
            "(Device cuda7/Epoch 3) Train Loss: 0.360 | Train Acc: 87.000 | Test Loss: 0.578 | Test Acc: 80.760\n",
            "(Device cuda11/Epoch 3) Train Loss: 0.367 | Train Acc: 86.980 | Test Loss: 0.586 | Test Acc: 80.930\n",
            "(Device cuda7/Epoch 3) Train Loss: 0.379 | Train Acc: 87.620 | Test Loss: 0.577 | Test Acc: 81.000\n",
            "(Device cuda48/Epoch 3) Train Loss: 0.372 | Train Acc: 87.480 | Test Loss: 0.586 | Test Acc: 80.750\n",
            "(Device cuda9/Epoch 3) Train Loss: 0.370 | Train Acc: 87.440 | Test Loss: 0.583 | Test Acc: 80.780\n",
            "(Device cuda33/Epoch 3) Train Loss: 0.331 | Train Acc: 88.700 | Test Loss: 0.583 | Test Acc: 80.920\n",
            "(Device cuda4/Epoch 3) Train Loss: 0.345 | Train Acc: 87.520 | Test Loss: 0.573 | Test Acc: 81.390\n",
            "(Device cuda45/Epoch 3) Train Loss: 0.304 | Train Acc: 89.500 | Test Loss: 0.572 | Test Acc: 81.130\n",
            "(Device cuda31/Epoch 3) Train Loss: 0.349 | Train Acc: 88.180 | Test Loss: 0.558 | Test Acc: 81.800\n",
            "(Device cuda15/Epoch 3) Train Loss: 0.350 | Train Acc: 88.260 | Test Loss: 0.574 | Test Acc: 81.390\n",
            "(Device cuda36/Epoch 3) Train Loss: 0.306 | Train Acc: 89.220 | Test Loss: 0.601 | Test Acc: 80.590\n",
            "(Device cuda34/Epoch 3) Train Loss: 0.327 | Train Acc: 88.460 | Test Loss: 0.588 | Test Acc: 80.990\n",
            "(Device cuda43/Epoch 3) Train Loss: 0.322 | Train Acc: 89.220 | Test Loss: 0.576 | Test Acc: 81.150\n",
            "(Device cuda13/Epoch 3) Train Loss: 0.314 | Train Acc: 89.420 | Test Loss: 0.573 | Test Acc: 81.170\n",
            "(Device cuda24/Epoch 3) Train Loss: 0.284 | Train Acc: 90.500 | Test Loss: 0.592 | Test Acc: 80.680\n",
            "(Device cuda25/Epoch 3) Train Loss: 0.312 | Train Acc: 89.100 | Test Loss: 0.577 | Test Acc: 81.160\n",
            "(Device cuda47/Epoch 3) Train Loss: 0.321 | Train Acc: 89.560 | Test Loss: 0.567 | Test Acc: 81.460\n",
            "(Device cuda49/Epoch 3) Train Loss: 0.312 | Train Acc: 89.460 | Test Loss: 0.569 | Test Acc: 81.450\n",
            "(Device cuda31/Epoch 3) Train Loss: 0.343 | Train Acc: 88.080 | Test Loss: 0.564 | Test Acc: 81.630\n",
            "(Device cuda15/Epoch 3) Train Loss: 0.322 | Train Acc: 88.860 | Test Loss: 0.557 | Test Acc: 81.790\n",
            "(Device cuda3/Epoch 3) Train Loss: 0.341 | Train Acc: 89.320 | Test Loss: 0.556 | Test Acc: 81.720\n",
            "(Device cuda11/Epoch 3) Train Loss: 0.302 | Train Acc: 89.420 | Test Loss: 0.560 | Test Acc: 81.720\n",
            "(Device cuda7/Epoch 3) Train Loss: 0.338 | Train Acc: 88.360 | Test Loss: 0.558 | Test Acc: 81.780\n",
            "(Device cuda16/Epoch 3) Train Loss: 0.335 | Train Acc: 88.320 | Test Loss: 0.556 | Test Acc: 81.850\n",
            "(Device cuda46/Epoch 3) Train Loss: 0.288 | Train Acc: 90.440 | Test Loss: 0.553 | Test Acc: 82.030\n",
            "(Device cuda5/Epoch 3) Train Loss: 0.287 | Train Acc: 90.840 | Test Loss: 0.555 | Test Acc: 81.830\n",
            "(Device cuda26/Epoch 3) Train Loss: 0.336 | Train Acc: 88.700 | Test Loss: 0.554 | Test Acc: 81.690\n",
            "(Device cuda4/Epoch 3) Train Loss: 0.315 | Train Acc: 89.140 | Test Loss: 0.556 | Test Acc: 81.710\n",
            "(Device cuda40/Epoch 3) Train Loss: 0.262 | Train Acc: 90.960 | Test Loss: 0.557 | Test Acc: 81.770\n",
            "(Device cuda29/Epoch 3) Train Loss: 0.338 | Train Acc: 88.080 | Test Loss: 0.555 | Test Acc: 81.680\n",
            "(Device cuda48/Epoch 3) Train Loss: 0.323 | Train Acc: 89.640 | Test Loss: 0.554 | Test Acc: 81.740\n",
            "(Device cuda22/Epoch 3) Train Loss: 0.312 | Train Acc: 89.620 | Test Loss: 0.556 | Test Acc: 81.830\n",
            "(Device cuda5/Epoch 3) Train Loss: 0.272 | Train Acc: 90.620 | Test Loss: 0.553 | Test Acc: 81.780\n",
            "(Device cuda32/Epoch 3) Train Loss: 0.282 | Train Acc: 90.140 | Test Loss: 0.553 | Test Acc: 81.800\n",
            "(Device cuda26/Epoch 3) Train Loss: 0.316 | Train Acc: 89.300 | Test Loss: 0.552 | Test Acc: 81.850\n",
            "(Device cuda21/Epoch 3) Train Loss: 0.321 | Train Acc: 89.140 | Test Loss: 0.550 | Test Acc: 81.940\n",
            "(Device cuda11/Epoch 3) Train Loss: 0.341 | Train Acc: 89.400 | Test Loss: 0.546 | Test Acc: 82.020\n",
            "(Device cuda8/Epoch 3) Train Loss: 0.324 | Train Acc: 88.800 | Test Loss: 0.549 | Test Acc: 82.020\n",
            "(Device cuda23/Epoch 3) Train Loss: 0.312 | Train Acc: 89.260 | Test Loss: 0.551 | Test Acc: 81.970\n",
            "(Device cuda37/Epoch 3) Train Loss: 0.311 | Train Acc: 89.200 | Test Loss: 0.550 | Test Acc: 82.060\n",
            "(Device cuda48/Epoch 3) Train Loss: 0.298 | Train Acc: 89.820 | Test Loss: 0.546 | Test Acc: 82.110\n",
            "(Device cuda45/Epoch 3) Train Loss: 0.270 | Train Acc: 90.700 | Test Loss: 0.548 | Test Acc: 82.160\n",
            "(Device cuda0/Epoch 3) Train Loss: 0.314 | Train Acc: 88.660 | Test Loss: 0.549 | Test Acc: 82.100\n",
            "(Device cuda20/Epoch 3) Train Loss: 0.327 | Train Acc: 88.800 | Test Loss: 0.549 | Test Acc: 82.120\n",
            "(Device cuda39/Epoch 3) Train Loss: 0.269 | Train Acc: 91.160 | Test Loss: 0.550 | Test Acc: 82.140\n",
            "(Device cuda49/Epoch 3) Train Loss: 0.332 | Train Acc: 88.880 | Test Loss: 0.549 | Test Acc: 82.070\n",
            "(Device cuda43/Epoch 3) Train Loss: 0.299 | Train Acc: 89.720 | Test Loss: 0.549 | Test Acc: 82.130\n",
            "(Device cuda24/Epoch 3) Train Loss: 0.307 | Train Acc: 90.180 | Test Loss: 0.549 | Test Acc: 82.060\n",
            "(Device cuda14/Epoch 3) Train Loss: 0.329 | Train Acc: 88.480 | Test Loss: 0.549 | Test Acc: 82.060\n",
            "(Device cuda2/Epoch 3) Train Loss: 0.330 | Train Acc: 88.840 | Test Loss: 0.549 | Test Acc: 82.080\n",
            "(Device cuda11/Epoch 3) Train Loss: 0.312 | Train Acc: 89.100 | Test Loss: 0.549 | Test Acc: 82.060\n",
            "(Device cuda40/Epoch 3) Train Loss: 0.264 | Train Acc: 91.220 | Test Loss: 0.548 | Test Acc: 82.110\n",
            "(Device cuda9/Epoch 3) Train Loss: 0.321 | Train Acc: 89.100 | Test Loss: 0.548 | Test Acc: 82.160\n",
            "(Device cuda47/Epoch 3) Train Loss: 0.324 | Train Acc: 89.100 | Test Loss: 0.549 | Test Acc: 82.160\n",
            "(Device cuda44/Epoch 3) Train Loss: 0.318 | Train Acc: 89.120 | Test Loss: 0.549 | Test Acc: 82.090\n",
            "(Device cuda10/Epoch 3) Train Loss: 0.320 | Train Acc: 88.920 | Test Loss: 0.550 | Test Acc: 82.110\n",
            "(Device cuda11/Epoch 3) Train Loss: 0.317 | Train Acc: 89.420 | Test Loss: 0.550 | Test Acc: 82.110\n",
            "(Device cuda10/Epoch 3) Train Loss: 0.326 | Train Acc: 88.360 | Test Loss: 0.549 | Test Acc: 82.150\n",
            "(Device cuda44/Epoch 3) Train Loss: 0.325 | Train Acc: 88.940 | Test Loss: 0.549 | Test Acc: 82.120\n",
            "(Device cuda23/Epoch 3) Train Loss: 0.315 | Train Acc: 89.100 | Test Loss: 0.549 | Test Acc: 82.110\n",
            "(Device cuda1/Epoch 3) Train Loss: 0.286 | Train Acc: 90.120 | Test Loss: 0.549 | Test Acc: 82.110\n",
            "(Device cuda14/Epoch 3) Train Loss: 0.364 | Train Acc: 88.280 | Test Loss: 0.549 | Test Acc: 82.020\n",
            "(Device cuda10/Epoch 3) Train Loss: 0.331 | Train Acc: 88.560 | Test Loss: 0.549 | Test Acc: 82.050\n",
            "(Device cuda40/Epoch 3) Train Loss: 0.274 | Train Acc: 90.520 | Test Loss: 0.549 | Test Acc: 82.040\n",
            "(Device cuda38/Epoch 3) Train Loss: 0.313 | Train Acc: 88.580 | Test Loss: 0.549 | Test Acc: 82.040\n",
            "(Device cuda12/Epoch 3) Train Loss: 0.317 | Train Acc: 90.000 | Test Loss: 0.549 | Test Acc: 82.070\n",
            "(Device cuda32/Epoch 3) Train Loss: 0.296 | Train Acc: 89.780 | Test Loss: 0.549 | Test Acc: 82.080\n",
            "(Device cuda26/Epoch 3) Train Loss: 0.317 | Train Acc: 89.120 | Test Loss: 0.548 | Test Acc: 82.070\n",
            "Total training time: 7220.901037931442 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KNmDbPh5b0h"
      },
      "source": [
        "---\n",
        "\n",
        "### **2. Non-IID Federated Learning and Fairness**\n",
        "\n",
        "---\n",
        "**Overview**\n",
        "\n",
        "In **PART 1**, you implemented a Federated Learning pipeline that operated on IID data.\n",
        "While this IID assumption may hold in some applications, it does not hold in many other settings.\n",
        "For example, a group of similar users may have data that is fundamentally different from that of another group of users.\n",
        "As a result, the aggregate data that federated learning operates on will be non-IID in nature.\n",
        "\n",
        "In **PART 2** of the assignment, you will explore using Federated Learning in a non-IID setting.\n",
        "In this part of the assignment, you will create groups of devices such that the inter-group data is non-IID and the intra-group data is IID.\n",
        "To do this, you will reimplement many of the functions you implemented in **PART 1** for this non-IID setting.\n",
        "\n",
        "For all experiments in this section, we assume there are three groups.\n",
        "Each group is assigned a different subset of classes in the dataset (Group 0 is assigned data from classes 0-3, Group 1 from classes 4-6, and Group 2 from classes 7-9).\n",
        "We also fix each group to contain 20 devices, although you will vary per-group participation rates in each round in **PART 2.4**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yUOGnkZCbp-"
      },
      "source": [
        "---\n",
        "**Non-IID Sampling**\n",
        "\n",
        "<font color='red'>**PART 2.1:**</font> [10 points]\n",
        "\n",
        "We will first start by implementing `noniid_group_sampler`, a new, non-IID group version of the `iid_sampler` you implemented in PART 1.  We will use this function to generate training subsets for multiple devices in PART 2.4.  \n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 2.1*, implement the `noniid_group_sampler` function to generate **non-IID** samples from the CIFAR-10 training set.\n",
        "As input, the function should take the dataset and number of training samples each device should be assigned.\n",
        "As in `iid_sampler` you implemented previously, the function should return a `dict` where each key is a device ID number and each value is a `set` of the indices of training samples in the dataset assigned to that device.\n",
        "You may want to have the function return other data as well, depending on how you implement functions in later parts of the assignment.\n",
        "We have provided the mapping that indicates which classes are mapped to each group.\n",
        "Within a given group, you should sample the data in an IID fashion.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VajsGz0wiL05"
      },
      "source": [
        "## Code Cell 2.1\n",
        "\n",
        "# creates noniid TRAINING datasets for each group\n",
        "def noniid_group_sampler(dataset, num_items_per_device):\n",
        "  '''\n",
        "    dataset: PyTorch Dataset (e.g., CIFAR-10 training set)\n",
        "    num_devices: integer number of devices to create subsets for\n",
        "    num_items_per_device: how many samples to assign to each device\n",
        "\n",
        "    return: a dictionary of the following format:\n",
        "      {\n",
        "        0: [3, 65, 2233, ..., 22] // device 0 sample indexes\n",
        "        1: [0, 2, 4, ..., 583] // device 1 sample indexes\n",
        "        ...\n",
        "      }\n",
        "\n",
        "  '''\n",
        "\n",
        "  # how many devices per non-iid group\n",
        "  devices_per_group = [20, 20, 20]\n",
        "\n",
        "  # label assignment per group\n",
        "  dict_group_classes = {}\n",
        "  dict_group_classes[0] = [0,1,2,3]\n",
        "  dict_group_classes[1] = [4,5,6]\n",
        "  dict_group_classes[2] = [7,8,9]\n",
        "\n",
        "  # Part 2.1: Implement!\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY1H2bOELzX5"
      },
      "source": [
        "---\n",
        "**Group-based Device Rejection**\n",
        "\n",
        "<font color='red'>**PART 2.2:**</font> [5 points]\n",
        "\n",
        "We will now implement `get_devices_for_round_GROUP`, a new group-based version of the `get_devices_for_round` you implemented in **PART 1**.\n",
        "We will use this function in **PART 2.4** to simulate the device rejection phase shown earlier on a per-group basis.  \n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 2.2*, implement the `get_devices_for_round_GROUP` function to generate a list of devices that will participate in each round of federated learning.\n",
        "The function should, at minimum, take as input 1) the list of all devices, and 2) how many devices from each group should participate in a given round.\n",
        "It should return a list of devices that will participate in a given round.\n",
        "You may want to add additional input parameters depending on your implementation strategy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akRqxN7mMjfa"
      },
      "source": [
        "## Code Cell 2.2\n",
        "\n",
        "# get which devices in each group should participate in a current round\n",
        "# by explicitly saying number of each devices desired for each group\n",
        "def get_devices_for_round_GROUP(devices, device_nums, user_group_idxs):\n",
        "  # PART 2.2: Implement!\n",
        "  # Assume first 20 are group 0, second 20 are group 1, third 20 are group 2\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBHBZVehNZNI"
      },
      "source": [
        "---\n",
        "**Group-based Testing**\n",
        "\n",
        "<font color='red'>**PART 2.3:**</font> [5 points]\n",
        "\n",
        "We will now implement the testing functions needed to evaluate the global model learned via Federated Learning on a per-group basis.  This will require two functions:\n",
        "\n",
        "\n",
        "\n",
        "* `cifar_noniid_group_test` divides the test dataset into three subsets, one subset for each group.\n",
        "* `test_group` gets per-group classification accuracy for the global model.\n",
        "You will likely want to start with the `test` function from **Code Cell 1.2** and modify it to work on a per-group basis.\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 2.3*, implement the `cifar_noniid_group_test` function to create a test dataset for each group.\n",
        "It should take the full CIFAR-10 test dataset as input, and return a `dict` where each key is a group ID, and each value is a `set` of the indices for all test samples for that group.\n",
        "\n",
        "2.  In *Code Cell 2.3*, implement the `test_group` function to output the per-group classification accuracy of the global model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99S3opJONpeW"
      },
      "source": [
        "## Code Cell 2.3\n",
        "\n",
        "# creates noniid TEST datasets for each group\n",
        "def cifar_noniid_group_test(dataset):\n",
        "\n",
        "  dict_group_classes = {}\n",
        "  dict_group_classes[0] = [0,1,2,3]\n",
        "  dict_group_classes[1] = [4,5,6]\n",
        "  dict_group_classes[2] = [7,8,9]\n",
        "\n",
        "  # Part 2.3: Implement!\n",
        "  pass\n",
        "\n",
        "# gets per-group accuracy of global model\n",
        "def test_group(epoch, device, group_idxs_dict):\n",
        "\n",
        "    # Part 2.3: Implement!\n",
        "    # Hint: refer to test function in PART 1\n",
        "    # Hint: check https://pytorch.org/docs/stable/data.html?highlight=subset#torch.utils.data.Subset\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtkYyNF5Oo9J"
      },
      "source": [
        "---\n",
        "**Federated Learning Results in Non-IID Setting**\n",
        "\n",
        "<font color='red'>**PART 2.4:**</font> [10 points]\n",
        "\n",
        "We will now run federated learning in the non-IID setting using the functions you previously wrote.\n",
        "We will examine two different scenarios.\n",
        "\n",
        "**Fair Device Participation:** run federated learning on the CIFAR-10 dataset with three groups.\n",
        "Each group should have exactly one device participate in each round.\n",
        "\n",
        "**Unfair Device Participation:** run federated learning on the CIFAR-10 dataset with three groups.\n",
        "Group 0 should have five devices participate in each round, and Groups 1 and 2 should each only have one device participate in each round.\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 2.4*, train a global model via federated learning for the group-based non-IID setting.  Much of the code has been given to you, but you will need to fill in the parts using calls to the group-based, non-iid functions you wrote above.\n",
        "(Hint: you will likely be able to re-use parts of the code you wrote in **Part 1.3**.)\n",
        "\n",
        "2. Graph the per-group test accuracy over 100 rounds for the **Fair Device Participation** scenario. Each group should have its own line in the graph.\n",
        "\n",
        "3.  Graph the per-group test accuracy over 100 rounds in the **Unfair Device Participation** scenario. Each group should have its own line in the graph.\n",
        "\n",
        "4.  Describe the differences you see between the two scenarios. How can you explain what you are seeing?  (100 words maximum)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eia5zgWx6ew3"
      },
      "source": [
        "## Code Cell 2.4\n",
        "\n",
        "rounds = 100\n",
        "local_epochs = 1\n",
        "num_items_per_device = 5000\n",
        "device_nums = [5, 1, 1]\n",
        "net = ConvNet().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "milestones=[250, 500, 750]\n",
        "\n",
        "# Part 2.4: Implement non-iid sampling\n",
        "data_idxs = noniid_group_sampler(trainset, num_items_per_device)\n",
        "\n",
        "# Part 2.4: Implement device creation here\n",
        "devices = [] # Implement this!\n",
        "\n",
        "test_idxs = cifar_noniid_group_test(testset)\n",
        "## Non-IID Federated Learning\n",
        "start_time = time.time()\n",
        "for round_num in range(rounds):\n",
        "\n",
        "    # Get devices for each round\n",
        "    round_devices = get_devices_for_round_GROUP(devices, device_nums, None)\n",
        "\n",
        "    print('Round: ', round_num)\n",
        "    for device in round_devices:\n",
        "        for local_epoch in range(local_epochs):\n",
        "            train(local_epoch, device)\n",
        "\n",
        "    # Weight averaging\n",
        "    w_avg = average_weights(round_devices)\n",
        "\n",
        "    for device in devices:\n",
        "        device['net'].load_state_dict(w_avg)\n",
        "        device['optimizer'].zero_grad()\n",
        "        device['optimizer'].step()\n",
        "        device['scheduler'].step()\n",
        "\n",
        "    # Test accuracy\n",
        "    test_group(round_num, device, test_idxs)\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print('Total training time: {} seconds'.format(total_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQB2URXWqB6m"
      },
      "source": [
        "----\n",
        "### **3. Quantization of Local Models for Reduced Communication Cost**\n",
        "-----\n",
        "Quantization refers to the process of reducing the number of bits used to represent a number. In the context of deep learning, the predominant numerical format used in research and deployment has been 32-bit floating-point ([IEEE 754 Format](https://en.wikipedia.org/wiki/Single-precision_floating-point_format)).\n",
        "However, the desire for reduced model size and computation has led to research on using fewer bits to represent numbers in deep learning models.\n",
        "This can impact several aspects of the pipeline, including computation, communication, and storage requirements.\n",
        "For example, in the context of federated learning, quantizing a client model from full (32-bit) precision to 8-bit precision will reduce the model size by ~4×.\n",
        "Furthermore, because the model size is reduced, the communication required for uploading a client model is also reduced by ~4× as well.\n",
        "\n",
        "However, this quantization comes with trade-offs.\n",
        "To see this, consider a full precision representation (32-bit floating point). This representation has a large dynamic range (from $-3.4\\times 10^{38}$ to $+3.4\\times10^{38}$) and high precision (about $7$ decimal digits).\n",
        "As a result, a full precision number can be seen as continuous data.\n",
        "In contrast, $n$-bit fixed-point representations are limited to $2^n$ discrete values.\n",
        "$n$-bit quantization generally refers to projecting a full precision weight to one of these $2^n$ discrete values by finding its nearest neighbor.  \n",
        "\n",
        "--------\n",
        "<font color='red'>**PART 3.1:**</font> [5 points]\n",
        "\n",
        "In this part, we will write a function to project full-precision numbers into $n$-bit fixed-point numbers.\n",
        "For example, suppose we want to project full-precision numbers in the range of $[0, 1]$ into an 8-bit fixed point representation, $\\frac{1}{2^8-1}\\times(0, 1, 2, 3, \\dots, 253, 254,255)$, where $\\frac{1}{2^8-1}$ is the **scale factor** of the 8-bit fixed-point representation.\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 3.1*, implement a function that converts full-precision numbers in the range $[0, 1]$ into $n$-bit fixed-point numbers.\n",
        "If your implementation is correct, it should return *'Output of Quantization Matches!'*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1D9azF-qBCF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5e2441-ba96-4f3f-b62b-14482acc41c5"
      },
      "source": [
        "## Code Cell 3.1\n",
        "\n",
        "def quantizer(input, nbit):\n",
        "    '''\n",
        "    input: full precision tensor in the range [0, 1]\n",
        "    return: quantized tensor\n",
        "    '''\n",
        "    # Part 3.1: Implement!\n",
        "    # Hint: torch.round\n",
        "    range = 2 ** nbit - 1\n",
        "\n",
        "    output = torch.round(input * range) / range\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "# Test Code\n",
        "test_data = torch.tensor([i/11 for i in range(11)])\n",
        "\n",
        "# ground truth results of 4-bit quantization\n",
        "ground_truth = torch.tensor([0.0000, 0.0667, 0.2000, 0.2667, 0.3333, 0.4667,\n",
        "                             0.5333, 0.6667, 0.7333, 0.8000, 0.9333])\n",
        "\n",
        "# output of your quantization function\n",
        "quantizer_output = quantizer(test_data, 4)\n",
        "\n",
        "if torch.allclose(quantizer_output, ground_truth, atol=1e-04):\n",
        "    print('Output of Quantization Matches!')\n",
        "else:\n",
        "    print('Output of Quantization DOES NOT Match!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output of Quantization Matches!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrvX-UzbqY4J"
      },
      "source": [
        "**Quantize Weights of Neural Networks**\n",
        "\n",
        "The quantizer in **PART 3.1** will quantize any full-precision number in the range of $[0, 1]$ into an $n$-bit fixed-point number.\n",
        "However, a weight $w$ in a neural network is not necessarily in the range $[0, 1]$.\n",
        "\n",
        "To use the quantizer in **PART 3.1**, we will first use a scaling function to transform weights into the range of $[0 ,1]$:\n",
        "$$\\tilde{w} = \\frac{w}{2 \\cdot \\max(|w|)} + \\frac{1}{2}$$\n",
        "where $2 \\cdot \\max(|w|)$ is the **adaptive scale**.\n",
        "\n",
        "Then, we quantize the transformed weights:\n",
        "$$\\hat{w} = \\text{quantizer}_{\\text{n-bit}}(\\tilde{w})$$\n",
        "After quantization, a reverse scaling function can be applied on $\\hat{w}$ to recover the original scale:\n",
        "\n",
        "$$w_q = 2 \\cdot \\max(|w|) \\cdot \\left( \\hat{w}-\\frac{1}{2} \\right)$$\n",
        "\n",
        "Combining these three equations, the expression we will use to get the quantized weights $w_q$ is as follows:\n",
        "$$w_q = 2 \\cdot \\max(|w|) \\cdot \\left[ \\text{quantizer}_{\\text{n-bit}} \\left( \\frac{w}{2\\max(|w|)} + \\frac{1}{2} \\right) - \\frac{1}{2} \\right]$$\n",
        "\n",
        "This equation is the **deterministic quantization function**.\n",
        "\n",
        "Following the method proposed by [DoReFa-Net](https://arxiv.org/abs/1606.06160), we enable *stochastic quantization* by adding extra noise $N(n) = \\frac{\\sigma}{2^n-1}$ to the transformed weights $\\tilde{w}$, where $\\sigma \\sim \\text{Uniform}(-0.5, 0.5)$ and $n$ is the number of bits.\n",
        "Generally, including such extra noise will coax the model into exploring more of the loss surface, helping the model escape local minima and improve model generalizability.  \n",
        "\n",
        "The final **stochastic quantization function** we will use to quantize layers of local models is:\n",
        "\n",
        "$$w_q = 2 \\cdot \\max(|w|) \\cdot \\left[ \\text{quantizer}_{\\text{n-bit}} \\left( \\frac{w}{2 \\cdot \\max(|w|)} + \\frac{1}{2} + N(n) \\right) - \\frac{1}{2} \\right]$$\n",
        "\n",
        "\n",
        "<font color='red'>**PART 3.2:**</font> [10 points]\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 3.2*, implement `dorefa_g(w, nbit, adaptive_scale=None)` using the **stochastic quantization function** shown above. Again, if your implementation is correct, it should return *'Output of Quantization Matches!'*.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGIOhKnWqXXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "064b8682-da8a-4e3a-9ab8-c32bef191115"
      },
      "source": [
        "## Code Cell 3.2\n",
        "\n",
        "def quantize_model(model, nbit):\n",
        "    '''\n",
        "    Used in Code Cell 3.3 to quantize the ConvNet model\n",
        "    '''\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "            m.weight.data, m.adaptive_scale = dorefa_g(m.weight, nbit)\n",
        "            if m.bias is not None:\n",
        "                m.bias.data,_ = dorefa_g(m.bias, nbit, m.adaptive_scale)\n",
        "\n",
        "def dorefa_g(w, nbit, adaptive_scale=None):\n",
        "    '''\n",
        "    w: a floating-point weight tensor to quantize\n",
        "    nbit: the number of bits in the quantized representation\n",
        "    adaptive_scale: the maximum scale value. if None, it is set to be the\n",
        "                    absolute maximum value in w.\n",
        "    '''\n",
        "    if adaptive_scale is None:\n",
        "        adaptive_scale = 2 * torch.max(torch.abs(w))\n",
        "\n",
        "    def N(n):\n",
        "        sigma = np.random.uniform(-.5, .5)\n",
        "        return sigma / (2**n - 1)\n",
        "\n",
        "    w_tilde = w / adaptive_scale + 1/2\n",
        "\n",
        "    w_q = adaptive_scale * (quantizer(w_tilde + N(nbit), nbit) - 1/2)\n",
        "\n",
        "    # Part 3.2: Implement based on stochastic quantization function above\n",
        "\n",
        "    # remove placeholder \"return w, adaptive_scale\" line below\n",
        "    # after you implement\n",
        "    return w_q, adaptive_scale\n",
        "\n",
        "\n",
        "# Test Code\n",
        "test_data = torch.tensor([i/11 for i in range(11)])\n",
        "\n",
        "# ground truth results of 4-bit quantization\n",
        "ground_truth = torch.tensor([-0.0606, 0.0606, 0.1818, 0.3030, 0.3030, 0.4242,\n",
        "                             0.5455, 0.5455, 0.7879, 0.7879, 0.9091])\n",
        "\n",
        "# output of your quantization function\n",
        "torch.manual_seed(43)\n",
        "quantizer_output, adaptive_scale = dorefa_g(test_data, 4)\n",
        "\n",
        "print(ground_truth)\n",
        "print(quantizer_output)\n",
        "if torch.allclose(quantizer_output, ground_truth, atol=1e-04):\n",
        "    print('Output of Quantization Matches!')\n",
        "else:\n",
        "    print('Output of Quantization DOES NOT Match!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0606,  0.0606,  0.1818,  0.3030,  0.3030,  0.4242,  0.5455,  0.5455,\n",
            "         0.7879,  0.7879,  0.9091])\n",
            "tensor([-0.0606,  0.0606,  0.1818,  0.1818,  0.3030,  0.4242,  0.5455,  0.5455,\n",
            "         0.6667,  0.7879,  0.9091])\n",
            "Output of Quantization DOES NOT Match!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaaBm5RcqmMx"
      },
      "source": [
        "**Reduce the Communication Overhead with Quantization**\n",
        "\n",
        "We will now explore the performance impact of quantization on federated learning. We will use the IID setting from **PART 1**. You will use the same federated learning code, but will first quantize each local model with the `quantize_model` function you wrote above before uploading to the central server (*Line 27, Code Cell 3.3*).\n",
        "\n",
        "<font color='red'>**PART 3.3:**</font> [10 points]\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 3.3*, run federated learning with the following two quantization settings (bit widths): `nbit=16` and `nbit=4`. Plot the accuracy of the global models over 100 rounds for the different bit widths: 32-bit (the full-precision baseline you ran previously), 16-bit, and 4-bit.  \n",
        "2. Discuss the accuracy difference between the global models across the three different bit width settings: 32-bit, 16-bit, and 4-bit. (100 words maximum)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUyOuVCpqrTI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "2745a3cb-360b-43ca-a6f4-86ac8cb3e0cf"
      },
      "source": [
        "## Code Cell 3.3\n",
        "\n",
        "# Part 3.2: Train two settings with nbit=16 and nbit=4.\n",
        "#           Compare against the floating-point performance\n",
        "#           of the final FL model trained in Part 1.3.\n",
        "\n",
        "def federated_learning_quantization(nbit):\n",
        "    rounds = 100 # Part 1.3: Change to 100 epochs\n",
        "    local_epochs = 4\n",
        "    num_devices = 50\n",
        "    device_pct = 0.1\n",
        "    data_pct = 0.1\n",
        "    net = ConvNet().cuda()\n",
        "    quantize_model(net, nbit)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    data_idxs = iid_sampler(trainset, num_devices, data_pct)\n",
        "\n",
        "    # Part 1.3: Implement device creation here\n",
        "    devices = [create_device(net, 'cuda' + str(i), trainset, data_idxs[i]) for i in range(num_devices)]\n",
        "    # print(len(devices))\n",
        "    # print(devices[0]['net'])\n",
        "    # round_devices = get_devices_for_round(devices, data_pct)\n",
        "\n",
        "    ## IID Federated Learning\n",
        "    start_time = time.time()\n",
        "    for round_num in range(rounds):\n",
        "        # Part 1.3: Implement getting devices for each round here\n",
        "\n",
        "        round_devices = get_devices_for_round(devices, data_pct)\n",
        "        # print('Round: ', round_num)\n",
        "        # print(len(round_devices))\n",
        "        # print(round_devices)\n",
        "        for device in round_devices:\n",
        "            # print(device)\n",
        "            for local_epoch in range(local_epochs):\n",
        "                train(local_epoch, device)\n",
        "\n",
        "        # Weight averaging\n",
        "        w_avg = average_weights(round_devices)\n",
        "\n",
        "        for device in devices:\n",
        "            device['net'].load_state_dict(w_avg)\n",
        "            device['optimizer'].zero_grad()\n",
        "            device['optimizer'].step()\n",
        "            device['scheduler'].step()\n",
        "\n",
        "        # test accuracy after aggregation\n",
        "        test(round_num, devices[0])\n",
        "\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print('Total training time: {} seconds'.format(total_time))\n",
        "\n",
        "federated_learning_quantization(nbit=16)\n",
        "\n",
        "federated_learning_quantization(nbit=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ab2c54a8b3d9>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total training time: {} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mfederated_learning_quantization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mfederated_learning_quantization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-ab2c54a8b3d9>\u001b[0m in \u001b[0;36mfederated_learning_quantization\u001b[0;34m(nbit)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Part 1.3: Implement device creation here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cuda0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mdevices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcreate_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cuda'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_devices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-08612fc5ed15>\u001b[0m in \u001b[0;36mcreate_device\u001b[0;34m(net, device_id, trainset, data_idxs, lr, milestones, batch_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmilestones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mdevice_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__deepcopy__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;34m\"Only Tensors created explicitly by the user \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;34m\"(graph leaves) support the deepcopy protocol at the moment.  \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment.  If you were attempting to deepcopy a module, this may be because of a torch.nn.utils.weight_norm usage, see https://github.com/pytorch/pytorch/pull/103001"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **4. Gradient Inversion Attacks to Federated Learning**\n",
        "\n",
        "In this part, you will explore gradient inversion attacks which may break privacy in federated learning. In federated learning, each client receives the current global weights of the network and sends weights updates (gradients) based on local data. But how secure is sharing weights gradients? The [Deep Leakage](https://arxiv.org/pdf/1906.08935.pdf) paper shows it is possible to recover data given weights gradients.\n",
        "To perform the attack, Deep Leakage first randomly generates a pair of \"dummy\" inputs and labels and then performs the usual forward and backwards computation.\n",
        "After deriving the dummy gradients from the dummy data, instead of optimizing model weights as in typical training, Deep Leakage optimizes the dummy inputs and labels to minimize the distance between dummy gradients and real gradients. You may refer to the paper for more details."
      ],
      "metadata": {
        "id": "ehxZ_h81CKXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Code Cell 4.1\n",
        "dst = torchvision.datasets.CIFAR100(\"./data\", download=True)\n",
        "tp = transforms.Compose([\n",
        "    transforms.Resize(32),\n",
        "    transforms.CenterCrop(32),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "tt = transforms.ToPILImage()\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "print(\"Running on %s\" % device)\n",
        "\n",
        "def label_to_onehot(target, num_classes=100):\n",
        "    target = torch.unsqueeze(target, 1)\n",
        "    onehot_target = torch.zeros(target.size(0), num_classes, device=target.device)\n",
        "    onehot_target.scatter_(1, target, 1)\n",
        "    return onehot_target\n",
        "\n",
        "def cross_entropy_for_onehot(pred, target):\n",
        "    return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), 1))\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    if hasattr(m, \"weight\"):\n",
        "        m.weight.data.uniform_(-0.5, 0.5)\n",
        "    if hasattr(m, \"bias\"):\n",
        "        m.bias.data.uniform_(-0.5, 0.5)\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        act = nn.Sigmoid\n",
        "        self.body = nn.Sequential(\n",
        "            nn.Conv2d(3, 12, kernel_size=5, padding=5//2, stride=2),\n",
        "            act(),\n",
        "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=2),\n",
        "            act(),\n",
        "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
        "            act(),\n",
        "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
        "            act(),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(768, 100)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.body(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        # print(out.size())\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "net = LeNet().to(device)\n",
        "\n",
        "net.apply(weights_init)\n",
        "criterion = cross_entropy_for_onehot\n",
        "\n",
        "######### one client #########\n",
        "img_index = 25\n",
        "gt_data = tp(dst[img_index][0]).to(device)\n",
        "gt_data = gt_data.view(1, *gt_data.size())\n",
        "gt_label = torch.Tensor([dst[img_index][1]]).long().to(device)\n",
        "gt_label = gt_label.view(1, )\n",
        "gt_onehot_label = label_to_onehot(gt_label, num_classes=100)\n",
        "\n",
        "plt.imshow(tt(gt_data[0].cpu()))\n",
        "plt.title(\"Ground truth image\")\n",
        "print(\"GT label is %d.\" % gt_label.item(), \"\\nOnehot label is %d.\" % torch.argmax(gt_onehot_label, dim=-1).item())\n",
        "\n",
        "# compute original gradient\n",
        "out = net(gt_data)\n",
        "y = criterion(out, gt_onehot_label)\n",
        "dy_dx = torch.autograd.grad(y, net.parameters())\n",
        "\n",
        "\n",
        "# share the gradients with the server\n",
        "original_dy_dx = list((_.detach().clone() for _ in dy_dx))\n",
        "\n",
        "\n",
        "def defense_method(dy_dx, defense_strategy):\n",
        "\n",
        "  if defense_strategy=='none':\n",
        "    # no defense\n",
        "    return dy_dx\n",
        "\n",
        "  elif defense_strategy=='pruning':\n",
        "    # PART 4.1: pruning\n",
        "    for grad in dy_dx:\n",
        "        flat_grad = grad.view(-1)\n",
        "        num = int(0.2 * len(flat_grad))\n",
        "        sorted_indices = flat_grad.argsort()\n",
        "        flat_grad[sorted_indices[:num]] = 0\n",
        "\n",
        "    return dy_dx\n",
        "\n",
        "  elif defense_strategy=='quantization':\n",
        "    # PART 4.1: quantization\n",
        "    for idx, grad in enumerate(dy_dx):\n",
        "        dy_dx[idx] = quantizer(grad, 4)\n",
        "\n",
        "    return dy_dx\n",
        "\n",
        "  elif defense_strategy=='noise':\n",
        "    # PART 4.1: noise injection\n",
        "    for idx, grad in enumerate(dy_dx):\n",
        "        dy_dx[idx] += 10**-3 * torch.randn(grad.shape).cuda()\n",
        "\n",
        "    return dy_dx\n",
        "\n",
        "\n",
        "original_dy_dx = defense_method(original_dy_dx, 'pruning')\n",
        "\n",
        "######### Start attack ##########\n",
        "\n",
        "# generate dummy data and label\n",
        "dummy_data = torch.randn(gt_data.size()).to(device).requires_grad_(True)\n",
        "dummy_label = torch.randn(gt_onehot_label.size()).to(device).requires_grad_(True)\n",
        "\n",
        "plt.imshow(tt(dummy_data[0].cpu()))\n",
        "plt.title(\"Dummy data\")\n",
        "print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
        "\n",
        "optimizer = torch.optim.LBFGS([dummy_data, dummy_label] )\n",
        "\n",
        "history = []\n",
        "for iters in range(300):\n",
        "    def closure():\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred = net(dummy_data)\n",
        "        dummy_onehot_label = F.softmax(dummy_label, dim=-1)\n",
        "        dummy_loss = criterion(pred, dummy_onehot_label) # TODO: fix the gt_label to dummy_label\n",
        "        dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
        "\n",
        "        grad_diff = 0\n",
        "        grad_count = 0\n",
        "        for gx, gy in zip(dummy_dy_dx, original_dy_dx): # TODO: fix the variables here\n",
        "            grad_diff += ((gx - gy) ** 2).sum()\n",
        "            grad_count += gx.nelement()\n",
        "        # grad_diff = grad_diff / grad_count * 1000\n",
        "        grad_diff.backward()\n",
        "\n",
        "        return grad_diff\n",
        "\n",
        "    optimizer.step(closure)\n",
        "    if iters % 10 == 0:\n",
        "        current_loss = closure()\n",
        "        print(iters, \"%.4f\" % current_loss.item())\n",
        "    history.append(tt(dummy_data[0].cpu()))\n",
        "\n"
      ],
      "metadata": {
        "id": "EPkQJuvpNQJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Code Cell 4.2\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i in range(30):\n",
        "  plt.subplot(3, 10, i + 1)\n",
        "  plt.imshow(history[i * 10])\n",
        "  plt.title(\"iter=%d\" % (i * 10))\n",
        "  plt.axis('off')\n",
        "print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())"
      ],
      "metadata": {
        "id": "ViVYjdl_uYue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>**PART 4.1:**</font> [15 points]\n",
        "\n",
        "In this part, we conduct a gradient inversion attack on a ConvNet model and implement several defense strategies. You will run experiments under 4 different settings:\n",
        "1. Baseline: original Deep Leakage without any defenses (we have provided this code in *Code Cell 4.1*)\n",
        "2. Noise: defend against the attack by injecting Gaussian noise $\\mathcal{N}(0, 10^{-3})$ to the weights gradients\n",
        "3. Pruning: defend against the attack by pruning gradients: use unstructured magnitude pruning to set 20% of the gradient values to zero.\n",
        "4. Quantization: defend against the attack by performing 4-bit quantization (`nbit=4`) on the gradients with the function you implemented in **PART 3.2**.\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "\n",
        "1. Implement the three defense strategies (i.e., noise injection, pruning, and quantization) `defense_method` in *Code Cell 4.1*.\n",
        "2. Run the 4 experiments (i.e., Baseline, Noise, Pruning, and Quantization). For each experiment, you should report: (1) the final inversion result as measured by $\\|\\text{image}-\\text{recovered_image}\\|_2$ and (2) the optimization process of inversion using *Code Cell 4.2*.\n",
        "3. Compare and discuss the effectiveness of the 3 different defense strategies. (100 words maximum)\n"
      ],
      "metadata": {
        "id": "Sc0OjDXzNXqo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K0cMu4r5wvXw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}