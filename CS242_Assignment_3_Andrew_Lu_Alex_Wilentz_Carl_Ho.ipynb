{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BRdPkqn04KqH"
      ],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewmlu/cs242-pa3/blob/main/CS242_Assignment_3_Andrew_Lu_Alex_Wilentz_Carl_Ho.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7ttBYeclcLI"
      },
      "source": [
        "# CS242: Assignment 3\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQGm6JtgehIq"
      },
      "source": [
        "> Harvard CS 242: Computing at Scale (Fall 2023)\n",
        "\n",
        ">\n",
        "> Instructor: Professor HT Kung\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRdPkqn04KqH"
      },
      "source": [
        "### **Assignment Instructions**\n",
        "\n",
        "**Please start this assignment early, especially those who are interested in doing a final project involving Federated Learning.**\n",
        "\n",
        "Read the following instructions carefully before starting the assignment and again before submitting your work:\n",
        "\n",
        "* This programming assignment must be completed with the same group you worked with in Assignment 2. **If you have any issues with this arrangement, please email Andrew immediately.**\n",
        "* We expect this assignment to take more time than Assignment 2. There is a more significant programming element involved, and more training time is required for the models. **Again, we suggest you start right away.**\n",
        "* The assignment consists of two parts: **this Google Colab file** (an .ipynb file) and a **LaTeX answer template**.\n",
        "* The Google Colab contains all assignment instructions and *Code Cells* that you will use to implement the programming components of the assignment in Python. **(Note: if there are any wording differences between the LaTeX template and this Colab file, the Colab file is authoritative and takes precedence.)**\n",
        "* We provide a significant amount of the code to make it easier to get started. In the *Code Cells*, please add comments to explain the purpose of each line of code in your implementation. **You will not receive credit for implementations that are not well-documented.**\n",
        "* <font color='red'>**Deliverables are highlighted in red**</font> in this Google Colab file. Use the LaTeX answer template to write down answers for these deliverables.\n",
        "* Each group will submit both a PDF of your answers and your Google Colab file (.ipynb file) containing all completed *Code cells* to \"Programming Assignment 3\" on Canvas. Only one submission per group. Check your .ipynb file using this [tool](https://htmtopdf.herokuapp.com/ipynbviewer/) before submitting to ensure that you completed all *Code Cells* (including detailed comments).\n",
        "* The assignment is due on **Wednesday, October 25, 2023 at 11:59 PM EST**.\n",
        "* Each part you are asked to implement is relatively small in isolation, and should be easy to test. We strongly recommend you test each of these parts before training the large models as to not waste time training models with buggy implementations. For example, you should ensure that your sampling is being done correctly, otherwise the model will still train, but your results will not be correct. For a number of sections, we have provided checks you can run to ensure correctness prior to training a large model.\n",
        "\n",
        "-----\n",
        "An outline of this assignment with point values and training estimates is given below. Note that these estimates represent a lower bound on the running time, assuming a correct implementation.\n",
        "\n",
        "1. **Exploring Federated Learning (FL)** [25 points] [Training Estimate: 2 hours]\n",
        "\n",
        "2. **Non-IID Federated Learning and Fairness** [30 points] [Training Estimate: 3 hours]\n",
        "\n",
        "3. **Quantization of Local Models for Reduced Communication Cost** [25 points] [Training Estimate: 3 hours]\n",
        "\n",
        "4. **Backdoor Attacks by Malicious Clients and Defenses** [15 points] [Training Estimate: 1.5 hours]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UvFA89jTuON"
      },
      "source": [
        "---\n",
        "\n",
        "### **1. Exploring Federated Learning (FL)**\n",
        "\n",
        "---\n",
        "We will be using a dataset (CIFAR-10) and CNN model (`ConvNet`) introduced in Programming Assignment 2. *Code Cell 1.1* creates the CIFAR-10 training and testing datasets. Additionally, it also contains the CNN (`ConvNet`)  that will be used throughout the assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9WL6HA_Lpe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e08062-d6cc-491b-bdec-f319dacda589"
      },
      "source": [
        "## Code Cell 1.1\n",
        "\n",
        "import time\n",
        "import copy\n",
        "import sys\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Using CIFAR-10 again as in Assignment 2\n",
        "# Load training data\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True,\n",
        "                                        transform=transform_train)\n",
        "\n",
        "# Load testing data\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True,\n",
        "                                       transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)\n",
        "\n",
        "\n",
        "# Using same ConvNet as in Assignment 2\n",
        "def conv_block(in_channels, out_channels, kernel_size=3, stride=1,\n",
        "               padding=1):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding,\n",
        "                  bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            conv_block(3, 32),\n",
        "            conv_block(32, 32),\n",
        "            conv_block(32, 64, stride=2),\n",
        "            conv_block(64, 64),\n",
        "            conv_block(64, 64),\n",
        "            conv_block(64, 128, stride=2),\n",
        "            conv_block(128, 128),\n",
        "            conv_block(128, 256),\n",
        "            conv_block(256, 256),\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "            )\n",
        "\n",
        "        self.classifier = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.model(x)\n",
        "        B, C, _, _ = h.shape\n",
        "        h = h.view(B, C)\n",
        "        return self.classifier(h)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 42290633.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjiB2IYp7B25"
      },
      "source": [
        "**Federated Learning Overview**\n",
        "\n",
        "Federated Learning (FL) distributes the task of training a deep neural network (such as our CNN `ConvNet`) across multiple client devices. Each client may have private data they do not want to share with a central server. Therefore, instead of transmitting data, clients perform training locally and send the updated model parameters (e.g., convolutional weights) to the server. The server averages these parameters across multiple clients to update the centralized model. Finally, after the centralized model has been updated, the server sends the new version of the model to all clients.\n",
        "\n",
        "The figure below depicts this Federated Learning paradigm (taken from [Towards Federated Learning at Scale: System Design](https://arxiv.org/pdf/1902.01046.pdf)). At the beginning of a training round in the selection phase, a percentage of devices (i.e., clients) agree to participate. By agreeing to participate, a client agrees to perform local training with its own dataset that resides on the device. During the configuration phase, the up-to-date centralized model is sent to the participating clients, which then perform local training. In the reporting phase, each client sends their own updated model (trained using local data) to the server for aggregation. Note that, in the figure, one of the clients fails to report back to the central server (either due to device or network failure). To simplify this assignment, we will assume this type of device/network failure is not possible.\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?id=1y8HAIxtNaZVLWetXHEzJ4UXWJ0yX_Jo0' />\n",
        "</figure>\n",
        "\n",
        "\n",
        "**Simulating Federated Learning**\n",
        "\n",
        "In this assignment, we will simulate this distributed Federated Learning environment on a single machine (i.e., a Colab instance). Each `device` will own a subset (or partition) of the dataset (e.g., 10% of the CIFAR-10 training set) and use it to train a local version of the model. The main difference between this simulated environment and a real system is the lack of networking between devices.\n",
        "\n",
        "You will use the `DatasetSplit` class in *Code Cell 1.2* to create subsets of the full training dataset. The `create_device` function creates a unique instance of `ConvNet`, an instance of the `DatasetSplit` dataloader, and an optimizer and scheduler for training. This function will be called multiple times (once per device) to create all the required device instances used for Federated Learning. The `train` and `test` functions are a modified version from Assignment 2 that take a device argument (the output from `create_device`. The batch size during training is set to 128 throughout the assignment. This is passed into the `create_device` function as a default parameter value (i.e., `batch_size=128`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSx1GxV2j0iI"
      },
      "source": [
        "## Code Cell 1.2\n",
        "import copy\n",
        "\n",
        "class DatasetSplit(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, idxs):\n",
        "        self.dataset = dataset\n",
        "        self.idxs = [int(i) for i in idxs]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idxs)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        image, label = self.dataset[self.idxs[item]]\n",
        "        return image, torch.tensor(label)\n",
        "\n",
        "def create_device(net, device_id, trainset, data_idxs, lr=0.1,\n",
        "                  milestones=None, batch_size=128):\n",
        "    if milestones == None:\n",
        "        milestones = [25, 50, 75]\n",
        "\n",
        "    device_net = copy.deepcopy(net)\n",
        "    optimizer = torch.optim.SGD(device_net.parameters(), lr=lr, momentum=0.9)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
        "                                                     milestones=milestones,\n",
        "                                                     gamma=0.1)\n",
        "    device_trainset = DatasetSplit(trainset, data_idxs)\n",
        "    device_trainloader = torch.utils.data.DataLoader(device_trainset,\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     shuffle=True)\n",
        "    return {\n",
        "        'net': device_net,\n",
        "        'id': device_id,\n",
        "        'dataloader': device_trainloader,\n",
        "        'optimizer': optimizer,\n",
        "        'scheduler': scheduler,\n",
        "        'train_loss_tracker': [],\n",
        "        'train_acc_tracker': [],\n",
        "        'test_loss_tracker': [],\n",
        "        'test_acc_tracker': [],\n",
        "        }\n",
        "\n",
        "def train(epoch, device):\n",
        "    net.train()\n",
        "    device['net'].train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(device['dataloader']):\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        device['optimizer'].zero_grad()\n",
        "        outputs = device['net'](inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        device['optimizer'].step()\n",
        "        train_loss += loss.item()\n",
        "        device['train_loss_tracker'].append(loss.item())\n",
        "        loss = train_loss / (batch_idx + 1)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        acc = 100. * correct / total\n",
        "        dev_id = device['id']\n",
        "        sys.stdout.write(f'\\r(Device {dev_id}/Epoch {epoch}) ' +\n",
        "                         f'Train Loss: {loss:.3f} | Train Acc: {acc:.3f}')\n",
        "        sys.stdout.flush()\n",
        "    device['train_acc_tracker'].append(acc)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def test(epoch, device):\n",
        "    net.eval()\n",
        "    test_loss, correct, total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = device['net'](inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "            device['test_loss_tracker'].append(loss.item())\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            loss = test_loss / (batch_idx + 1)\n",
        "            acc = 100.* correct / total\n",
        "    sys.stdout.write(f' | Test Loss: {loss:.3f} | Test Acc: {acc:.3f}\\n')\n",
        "    sys.stdout.flush()\n",
        "    acc = 100.*correct/total\n",
        "    device['test_acc_tracker'].append(acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTEyxu91KNl-"
      },
      "source": [
        "**Single Device Scenario**\n",
        "\n",
        "Before implementing Federated Learning, we will train a model for a single client device using only local data without sending updates to a central server. By doing this, the device is only able to look at a small percentage of the CIFAR-10 training set (10% in this case), and should perform poorly.\n",
        "\n",
        "---\n",
        "<font color='red'>**PART 1.1:**</font> [5 points]\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 1.3*, implement the function `iid_sampler` to generate **IID** (independent and identically distributed) samples from the CIFAR-10 training set. We will use this function to generate training subsets for multiple devices in **PART 1.2**.\n",
        "2. In *Code Cell 1.4*, create a single device using the function `create_device`. This device should have 10% of the CIFAR-10 training set, obtained using `iid_sampler`.\n",
        "3. Train the model for 1000 epochs using the parameters specified in *Code Cell 1.4* (similar to Assignment 2). The number of epochs is 10x greater due to the single device having only 10% of the data. Plot the test accuracy (`device['test_acc_tracker']`) over the epochs and comment on the classification accuracy compared to using 100% of the dataset as in Assignment 2. (50 words maximum)\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-t76gDhjr-Z"
      },
      "source": [
        "## Code Cell 1.3\n",
        "\n",
        "def iid_sampler(dataset, num_devices, data_pct):\n",
        "    '''\n",
        "    dataset: PyTorch Dataset (e.g., CIFAR-10 training set)\n",
        "    num_devices: integer number of devices to create subsets for\n",
        "    data_pct: percentage of training samples to give each device\n",
        "              e.g., 0.1 represents 10%\n",
        "\n",
        "    return: a dictionary of the following format:\n",
        "      {\n",
        "        0: [3, 65, 2233, ..., 22] // device 0 sample indexes\n",
        "        1: [0, 2, 4, ..., 583] // device 1 sample indexes\n",
        "        ...\n",
        "      }\n",
        "\n",
        "    iid (independent and identically distributed) means that the indexes\n",
        "    should be drawn independently in a uniformly random fashion.\n",
        "    '''\n",
        "\n",
        "    # total number of samples in the dataset\n",
        "    total_samples = len(dataset)\n",
        "    num_samples = int(data_pct * total_samples)\n",
        "\n",
        "    # Part 1.1: Implement!\n",
        "    sampled = {}\n",
        "    for i in range(num_devices):\n",
        "      # rand_indices = torch.randint(0, total_samples, num_samples)\n",
        "\n",
        "      sampled[i] = random_sampler = torch.utils.data.RandomSampler(dataset, num_samples=num_samples)\n",
        "\n",
        "    return sampled\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifc4z-2Q8ab2"
      },
      "source": [
        "Now, perform training using a single device on a subset of the training dataset using your `iid_sampler`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLd3fFeS8VEN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "ef232b95-7863-4d11-da1a-b9b4d6f68c09"
      },
      "source": [
        "## Code Cell 1.4\n",
        "\n",
        "data_pct = 0.1\n",
        "epochs = 100 # Part 1.1: Change to 1000 epochs\n",
        "num_devices = 1\n",
        "device_pct = 0.1\n",
        "net = ConvNet().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "milestones = [250, 500, 750]\n",
        "\n",
        "# Part 1.1: Implement the cifar iid_sampler to generate data_idxs for create_device\n",
        "data_idxs = iid_sampler(trainset, num_devices, data_pct)\n",
        "\n",
        "# Part 1.1: Create the device\n",
        "device = {\n",
        "    'net': net,\n",
        "    'dataloader': torch.utils.data.DataLoader(trainset, batch_size=32, sampler=data_idxs[0]),\n",
        "    'optimizer': torch.optim.Adam(net.parameters(), lr=1e-3),\n",
        "    'scheduler': torch.optim.lr_scheduler.MultiStepLR(net.parameters(), milestones=milestones, gamma=0.1)\n",
        "}\n",
        "\n",
        "# Part 1.1: Train the device model for 100 epochs and plot the result\n",
        "# Standard Training Loop\n",
        "start_time = time.time()\n",
        "for epoch in range(epochs):\n",
        "    train(epoch, device)\n",
        "    # To speed up running time, only evaluate the test set every 10 epochs\n",
        "    if epoch > 0 and epoch % 10 == 0:\n",
        "        test(epoch, device)\n",
        "    device['scheduler'].step()\n",
        "\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print('Total training time: {} seconds'.format(total_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-136d4b1ca079>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m'dataloader'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;34m'scheduler'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmilestones\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmilestones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m }\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, optimizer, milestones, gamma, last_epoch, verbose)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmilestones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmilestones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, optimizer, last_epoch, verbose)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Attach optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{type(optimizer).__name__} is not an Optimizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: generator is not an Optimizer"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4waD2ZlQI4X2"
      },
      "source": [
        "**Implementing Components for Federated Learning**\n",
        "\n",
        "In **PART 1.1**, you implemented `iid_sampler`, created a 10% subset of the CIFAR-10 training set, and used it to train a single client device model. Since the client only had a 10% subset of the full CIFAR-10 training set, it performed significantly worse than the same model trained on the entire training set.\n",
        "\n",
        "Federated Learning aims to improve the performance of these client devices by averaging the updates from multiple clients over the course of training. This way, a centralized server is able to be updated using the training data stored on local devices without having access to the training data.\n",
        "By using more client devices, you will be able to leverage the entire dataset.\n",
        "In a way, this simulates traditional gradient descent, but with additional epochs performed on each client before averaging, where each epoch uses mini-batches of size 128.\n",
        "An additional benefit of federated learning is that the centralized server does not require large compute resources, as most of the training computation is performed on local devices.\n",
        "This makes the training computation \"free\" for the centralized server, as the clients pay the compute cost on their local devices.\n",
        "\n",
        "---\n",
        "<font color='red'>**PART 1.2:**</font> [10 points]\n",
        "\n",
        "Before implementing Federated Learning, you must implement two functions which will be used during the training process.\n",
        "\n",
        "The `average_weights` function takes in multiple device models, and computes the average for each model parameter across all models. This function will be called by the centralized server to aggregate the training performed by the end user devices. This averaging is done in 32-bit floating point (`float32`).\n",
        "\n",
        "The `get_devices_for_round` function will be used to simulate the device rejection phase shown earlier in the figure in the **Federated Learning Overview** section. This function will select a percentage of devices to participate in each training round.\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 1.5*, implement `average_weights`. We have provided test code you can use to validate your implementation. This test code will also be useful for the full implementation of Federated Learning in **PART 1.3**.\n",
        "2. In *Code Cell 1.5*, implement the `get_devices_for_round` function. Try multiple `device_pct` settings to ensure that it is working properly.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X0fTWKg6hBY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "ce749780-4ff2-4987-eee2-f3dff87498cf"
      },
      "source": [
        "## Code Cell 1.5\n",
        "import copy\n",
        "\n",
        "\n",
        "def average_weights(devices):\n",
        "    '''\n",
        "    devices: a list of devices generated by create_devices\n",
        "    Returns an the average of the weights.\n",
        "    '''\n",
        "    # Part 1.2: Implement!\n",
        "    # Hint: device['net'].state_dict() will return an OrderedDict of all\n",
        "    #       tensors in the model. Return the average of each tensor using\n",
        "    #       and OrderedDict so that you can update the global model using\n",
        "    #       device['net'].load_state_dict(w_avg), where w_avg is the\n",
        "    #       averaged OrderedDict over all devices\n",
        "\n",
        "\n",
        "def get_devices_for_round(devices, device_pct):\n",
        "    '''\n",
        "    '''\n",
        "    # Part 1.2: Implement!\n",
        "\n",
        "# Test code for average_weights\n",
        "# Hint: This test may be useful for Part 1.3!\n",
        "class TestNetwork(nn.Module):\n",
        "    '''\n",
        "    A simple 2 layer MLP used for testing your average_weights implementation.\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(TestNetwork, self).__init__()\n",
        "        self.layer1 = nn.Linear(2, 2)\n",
        "        self.layer2 = nn.Linear(2, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.layer1(x))\n",
        "        return self.layer2(h)\n",
        "\n",
        "data_pct = 0.05\n",
        "num_devices = 2\n",
        "net = TestNetwork()\n",
        "data_idxs = iid_sampler(trainset, num_devices, data_pct)\n",
        "devices = [create_device(net, i, trainset, data_idxs[i])\n",
        "           for i in range(num_devices)]\n",
        "\n",
        "# Fixed seeding to compare against precomputed correct_weight_averages below\n",
        "torch.manual_seed(0)\n",
        "devices[0]['net'].layer1.weight.data.normal_()\n",
        "devices[0]['net'].layer1.bias.data.normal_()\n",
        "devices[0]['net'].layer2.weight.data.normal_()\n",
        "devices[0]['net'].layer2.bias.data.normal_()\n",
        "devices[1]['net'].layer1.weight.data.normal_()\n",
        "devices[1]['net'].layer1.bias.data.normal_()\n",
        "devices[1]['net'].layer2.weight.data.normal_()\n",
        "devices[1]['net'].layer2.bias.data.normal_()\n",
        "\n",
        "# Precomputed correct averages\n",
        "correct_weight_averages = OrderedDict(\n",
        "    [('layer1.weight', torch.tensor([[ 0.3245, -0.9013], [-0.9042,  1.0125]])),\n",
        "     ('layer1.bias', torch.tensor([-0.0724, -0.3119])),\n",
        "     ('layer2.weight', torch.tensor([[0.2976,  1.0509], [-1.0048, -0.5972],\n",
        "                                     [-0.3088, -0.2682], [-0.1690, -0.1060]])),\n",
        "     ('layer2.bias', torch.tensor([-0.4396,  0.3327, -1.3925,  0.3160]))\n",
        "    ])\n",
        "\n",
        "# Computed weight averages\n",
        "computed_weight_averages = average_weights(devices)\n",
        "\n",
        "mismatch_found = False\n",
        "for correct, computed in zip(correct_weight_averages.items(),\n",
        "                             computed_weight_averages.items()):\n",
        "    if not torch.allclose(correct[1], computed[1], atol=1e-2):\n",
        "        mismatch_found = True\n",
        "        print('Mismatch in tensor:', correct[0])\n",
        "\n",
        "if not mismatch_found:\n",
        "    print('Implementation output matches!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-cedff117525d>\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mmismatch_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m for correct, computed in zip(correct_weight_averages.items(),\n\u001b[0;32m---> 70\u001b[0;31m                              computed_weight_averages.items()):\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mmismatch_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgzNJfpM4kUj"
      },
      "source": [
        "**Federated Learning Training**\n",
        "\n",
        "---\n",
        "<font color='red'>**PART 1.3:**</font> [10 points]\n",
        "\n",
        "We will now run the federated learning in the IID setting using the functions you previously wrote in this section.\n",
        "The parameters are given to you in the code.\n",
        "You will use 100 rounds of federated learning updates.\n",
        "For each round, each device that participates in a given round will complete 4 epochs of local training.\n",
        "10% of devices should participate in each round, selected by the `get_devices_for_round` function you wrote previously.\n",
        "Note that we use static initialization for the models between all parts of the assignment.\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 1.6*, train a global model via federated learning.\n",
        "Much of the code has been given to you, but you will need to fill in the parts using calls to the functions you wrote above.\n",
        "\n",
        "2. Graph the accuracy of the global model over 100 rounds.\n",
        "Discuss the accuracy difference between the global model trained here and the individual local model you trained in **PART 1.1**. (50 words maximum)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8OZxTJK4m8S"
      },
      "source": [
        "## Code Cell 1.6\n",
        "\n",
        "# use these parameters\n",
        "rounds = 10 # Part 1.3: Change to 100 epochs\n",
        "local_epochs = 4\n",
        "num_devices = 50\n",
        "device_pct = 0.1\n",
        "data_pct = 0.1\n",
        "net = ConvNet().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "data_idxs = iid_sampler(trainset, num_devices, data_pct)\n",
        "\n",
        "# Part 1.3: Implement device creation here\n",
        "devices = None # Implement this!\n",
        "\n",
        "\n",
        "## IID Federated Learning\n",
        "start_time = time.time()\n",
        "for round_num in range(rounds):\n",
        "    # Part 1.3: Implement getting devices for each round here\n",
        "\n",
        "    print('Round: ', round_num)\n",
        "    for device in round_devices:\n",
        "        for local_epoch in range(local_epochs):\n",
        "            train(local_epoch, device)\n",
        "\n",
        "    # Weight averaging\n",
        "    w_avg = average_weights(round_devices)\n",
        "\n",
        "    for device in devices:\n",
        "        device['net'].load_state_dict(w_avg)\n",
        "        device['optimizer'].zero_grad()\n",
        "        device['optimizer'].step()\n",
        "        device['scheduler'].step()\n",
        "\n",
        "    # test accuracy after aggregation\n",
        "    test(round_num, devices[0])\n",
        "\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print('Total training time: {} seconds'.format(total_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KNmDbPh5b0h"
      },
      "source": [
        "---\n",
        "\n",
        "### **2. Non-IID Federated Learning and Fairness**\n",
        "\n",
        "---\n",
        "**Overview**\n",
        "\n",
        "In **PART 1**, you implemented a Federated Learning pipeline that operated on IID data.\n",
        "While this IID assumption may hold in some applications, it does not hold in many other settings.\n",
        "For example, a group of similar users may have data that is fundamentally different from that of another group of users.\n",
        "As a result, the aggregate data that federated learning operates on will be non-IID in nature.\n",
        "\n",
        "In **PART 2** of the assignment, you will explore using Federated Learning in a non-IID setting.\n",
        "In this part of the assignment, you will create groups of devices such that the inter-group data is non-IID and the intra-group data is IID.\n",
        "To do this, you will reimplement many of the functions you implemented in **PART 1** for this non-IID setting.\n",
        "\n",
        "For all experiments in this section, we assume there are three groups.\n",
        "Each group is assigned a different subset of classes in the dataset (Group 0 is assigned data from classes 0-3, Group 1 from classes 4-6, and Group 2 from classes 7-9).\n",
        "We also fix each group to contain 20 devices, although you will vary per-group participation rates in each round in **PART 2.4**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yUOGnkZCbp-"
      },
      "source": [
        "---\n",
        "**Non-IID Sampling**\n",
        "\n",
        "<font color='red'>**PART 2.1:**</font> [10 points]\n",
        "\n",
        "We will first start by implementing `noniid_group_sampler`, a new, non-IID group version of the `iid_sampler` you implemented in PART 1.  We will use this function to generate training subsets for multiple devices in PART 2.4.  \n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 2.1*, implement the `noniid_group_sampler` function to generate **non-IID** samples from the CIFAR-10 training set.\n",
        "As input, the function should take the dataset and number of training samples each device should be assigned.\n",
        "As in `iid_sampler` you implemented previously, the function should return a `dict` where each key is a device ID number and each value is a `set` of the indices of training samples in the dataset assigned to that device.\n",
        "You may want to have the function return other data as well, depending on how you implement functions in later parts of the assignment.\n",
        "We have provided the mapping that indicates which classes are mapped to each group.\n",
        "Within a given group, you should sample the data in an IID fashion.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VajsGz0wiL05"
      },
      "source": [
        "## Code Cell 2.1\n",
        "\n",
        "# creates noniid TRAINING datasets for each group\n",
        "def noniid_group_sampler(dataset, num_items_per_device):\n",
        "  '''\n",
        "    dataset: PyTorch Dataset (e.g., CIFAR-10 training set)\n",
        "    num_devices: integer number of devices to create subsets for\n",
        "    num_items_per_device: how many samples to assign to each device\n",
        "\n",
        "    return: a dictionary of the following format:\n",
        "      {\n",
        "        0: [3, 65, 2233, ..., 22] // device 0 sample indexes\n",
        "        1: [0, 2, 4, ..., 583] // device 1 sample indexes\n",
        "        ...\n",
        "      }\n",
        "\n",
        "  '''\n",
        "\n",
        "  # how many devices per non-iid group\n",
        "  devices_per_group = [20, 20, 20]\n",
        "\n",
        "  # label assignment per group\n",
        "  dict_group_classes = {}\n",
        "  dict_group_classes[0] = [0,1,2,3]\n",
        "  dict_group_classes[1] = [4,5,6]\n",
        "  dict_group_classes[2] = [7,8,9]\n",
        "\n",
        "  # Part 2.1: Implement!\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY1H2bOELzX5"
      },
      "source": [
        "---\n",
        "**Group-based Device Rejection**\n",
        "\n",
        "<font color='red'>**PART 2.2:**</font> [5 points]\n",
        "\n",
        "We will now implement `get_devices_for_round_GROUP`, a new group-based version of the `get_devices_for_round` you implemented in **PART 1**.\n",
        "We will use this function in **PART 2.4** to simulate the device rejection phase shown earlier on a per-group basis.  \n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 2.2*, implement the `get_devices_for_round_GROUP` function to generate a list of devices that will participate in each round of federated learning.\n",
        "The function should, at minimum, take as input 1) the list of all devices, and 2) how many devices from each group should participate in a given round.\n",
        "It should return a list of devices that will participate in a given round.\n",
        "You may want to add additional input parameters depending on your implementation strategy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akRqxN7mMjfa"
      },
      "source": [
        "## Code Cell 2.2\n",
        "\n",
        "# get which devices in each group should participate in a current round\n",
        "# by explicitly saying number of each devices desired for each group\n",
        "def get_devices_for_round_GROUP(devices, device_nums, user_group_idxs):\n",
        "  # PART 2.2: Implement!\n",
        "  # Assume first 20 are group 0, second 20 are group 1, third 20 are group 2\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBHBZVehNZNI"
      },
      "source": [
        "---\n",
        "**Group-based Testing**\n",
        "\n",
        "<font color='red'>**PART 2.3:**</font> [5 points]\n",
        "\n",
        "We will now implement the testing functions needed to evaluate the global model learned via Federated Learning on a per-group basis.  This will require two functions:\n",
        "\n",
        "\n",
        "\n",
        "* `cifar_noniid_group_test` divides the test dataset into three subsets, one subset for each group.\n",
        "* `test_group` gets per-group classification accuracy for the global model.\n",
        "You will likely want to start with the `test` function from **Code Cell 1.2** and modify it to work on a per-group basis.\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 2.3*, implement the `cifar_noniid_group_test` function to create a test dataset for each group.\n",
        "It should take the full CIFAR-10 test dataset as input, and return a `dict` where each key is a group ID, and each value is a `set` of the indices for all test samples for that group.\n",
        "\n",
        "2.  In *Code Cell 2.3*, implement the `test_group` function to output the per-group classification accuracy of the global model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99S3opJONpeW"
      },
      "source": [
        "## Code Cell 2.3\n",
        "\n",
        "# creates noniid TEST datasets for each group\n",
        "def cifar_noniid_group_test(dataset):\n",
        "\n",
        "  dict_group_classes = {}\n",
        "  dict_group_classes[0] = [0,1,2,3]\n",
        "  dict_group_classes[1] = [4,5,6]\n",
        "  dict_group_classes[2] = [7,8,9]\n",
        "\n",
        "  # Part 2.3: Implement!\n",
        "  pass\n",
        "\n",
        "# gets per-group accuracy of global model\n",
        "def test_group(epoch, device, group_idxs_dict):\n",
        "\n",
        "    # Part 2.3: Implement!\n",
        "    # Hint: refer to test function in PART 1\n",
        "    # Hint: check https://pytorch.org/docs/stable/data.html?highlight=subset#torch.utils.data.Subset\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtkYyNF5Oo9J"
      },
      "source": [
        "---\n",
        "**Federated Learning Results in Non-IID Setting**\n",
        "\n",
        "<font color='red'>**PART 2.4:**</font> [10 points]\n",
        "\n",
        "We will now run federated learning in the non-IID setting using the functions you previously wrote.\n",
        "We will examine two different scenarios.\n",
        "\n",
        "**Fair Device Participation:** run federated learning on the CIFAR-10 dataset with three groups.\n",
        "Each group should have exactly one device participate in each round.\n",
        "\n",
        "**Unfair Device Participation:** run federated learning on the CIFAR-10 dataset with three groups.\n",
        "Group 0 should have five devices participate in each round, and Groups 1 and 2 should each only have one device participate in each round.\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 2.4*, train a global model via federated learning for the group-based non-IID setting.  Much of the code has been given to you, but you will need to fill in the parts using calls to the group-based, non-iid functions you wrote above.\n",
        "(Hint: you will likely be able to re-use parts of the code you wrote in **Part 1.3**.)\n",
        "\n",
        "2. Graph the per-group test accuracy over 100 rounds for the **Fair Device Participation** scenario. Each group should have its own line in the graph.\n",
        "\n",
        "3.  Graph the per-group test accuracy over 100 rounds in the **Unfair Device Participation** scenario. Each group should have its own line in the graph.\n",
        "\n",
        "4.  Describe the differences you see between the two scenarios. How can you explain what you are seeing?  (100 words maximum)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eia5zgWx6ew3"
      },
      "source": [
        "## Code Cell 2.4\n",
        "\n",
        "rounds = 100\n",
        "local_epochs = 1\n",
        "num_items_per_device = 5000\n",
        "device_nums = [5, 1, 1]\n",
        "net = ConvNet().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "milestones=[250, 500, 750]\n",
        "\n",
        "# Part 2.4: Implement non-iid sampling\n",
        "data_idxs = noniid_group_sampler(trainset, num_items_per_device)\n",
        "\n",
        "# Part 2.4: Implement device creation here\n",
        "devices = [] # Implement this!\n",
        "\n",
        "test_idxs = cifar_noniid_group_test(testset)\n",
        "## Non-IID Federated Learning\n",
        "start_time = time.time()\n",
        "for round_num in range(rounds):\n",
        "\n",
        "    # Get devices for each round\n",
        "    round_devices = get_devices_for_round_GROUP(devices, device_nums, None)\n",
        "\n",
        "    print('Round: ', round_num)\n",
        "    for device in round_devices:\n",
        "        for local_epoch in range(local_epochs):\n",
        "            train(local_epoch, device)\n",
        "\n",
        "    # Weight averaging\n",
        "    w_avg = average_weights(round_devices)\n",
        "\n",
        "    for device in devices:\n",
        "        device['net'].load_state_dict(w_avg)\n",
        "        device['optimizer'].zero_grad()\n",
        "        device['optimizer'].step()\n",
        "        device['scheduler'].step()\n",
        "\n",
        "    # Test accuracy\n",
        "    test_group(round_num, device, test_idxs)\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print('Total training time: {} seconds'.format(total_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQB2URXWqB6m"
      },
      "source": [
        "----\n",
        "### **3. Quantization of Local Models for Reduced Communication Cost**\n",
        "-----\n",
        "Quantization refers to the process of reducing the number of bits used to represent a number. In the context of deep learning, the predominant numerical format used in research and deployment has been 32-bit floating-point ([IEEE 754 Format](https://en.wikipedia.org/wiki/Single-precision_floating-point_format)).\n",
        "However, the desire for reduced model size and computation has led to research on using fewer bits to represent numbers in deep learning models.\n",
        "This can impact several aspects of the pipeline, including computation, communication, and storage requirements.\n",
        "For example, in the context of federated learning, quantizing a client model from full (32-bit) precision to 8-bit precision will reduce the model size by ~4×.\n",
        "Furthermore, because the model size is reduced, the communication required for uploading a client model is also reduced by ~4× as well.\n",
        "\n",
        "However, this quantization comes with trade-offs.\n",
        "To see this, consider a full precision representation (32-bit floating point). This representation has a large dynamic range (from $-3.4\\times 10^{38}$ to $+3.4\\times10^{38}$) and high precision (about $7$ decimal digits).\n",
        "As a result, a full precision number can be seen as continuous data.\n",
        "In contrast, $n$-bit fixed-point representations are limited to $2^n$ discrete values.\n",
        "$n$-bit quantization generally refers to projecting a full precision weight to one of these $2^n$ discrete values by finding its nearest neighbor.  \n",
        "\n",
        "--------\n",
        "<font color='red'>**PART 3.1:**</font> [5 points]\n",
        "\n",
        "In this part, we will write a function to project full-precision numbers into $n$-bit fixed-point numbers.\n",
        "For example, suppose we want to project full-precision numbers in the range of $[0, 1]$ into an 8-bit fixed point representation, $\\frac{1}{2^8-1}\\times(0, 1, 2, 3, \\dots, 253, 254,255)$, where $\\frac{1}{2^8-1}$ is the **scale factor** of the 8-bit fixed-point representation.\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 3.1*, implement a function that converts full-precision numbers in the range $[0, 1]$ into $n$-bit fixed-point numbers.\n",
        "If your implementation is correct, it should return *'Output of Quantization Matches!'*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1D9azF-qBCF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d888c1-d664-443e-fab2-a797d57fa878"
      },
      "source": [
        "## Code Cell 3.1\n",
        "\n",
        "def quantizer(input, nbit):\n",
        "    '''\n",
        "    input: full precision tensor in the range [0, 1]\n",
        "    return: quantized tensor\n",
        "    '''\n",
        "    # Part 3.1: Implement!\n",
        "    # Hint: torch.round\n",
        "    range = 2 ** nbit - 1\n",
        "\n",
        "    output = torch.round(input * range) / range\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "# Test Code\n",
        "test_data = torch.tensor([i/11 for i in range(11)])\n",
        "\n",
        "# ground truth results of 4-bit quantization\n",
        "ground_truth = torch.tensor([0.0000, 0.0667, 0.2000, 0.2667, 0.3333, 0.4667,\n",
        "                             0.5333, 0.6667, 0.7333, 0.8000, 0.9333])\n",
        "\n",
        "# output of your quantization function\n",
        "quantizer_output = quantizer(test_data, 4)\n",
        "\n",
        "if torch.allclose(quantizer_output, ground_truth, atol=1e-04):\n",
        "    print('Output of Quantization Matches!')\n",
        "else:\n",
        "    print('Output of Quantization DOES NOT Match!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output of Quantization Matches!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrvX-UzbqY4J"
      },
      "source": [
        "**Quantize Weights of Neural Networks**\n",
        "\n",
        "The quantizer in **PART 3.1** will quantize any full-precision number in the range of $[0, 1]$ into an $n$-bit fixed-point number.\n",
        "However, a weight $w$ in a neural network is not necessarily in the range $[0, 1]$.\n",
        "\n",
        "To use the quantizer in **PART 3.1**, we will first use a scaling function to transform weights into the range of $[0 ,1]$:\n",
        "$$\\tilde{w} = \\frac{w}{2 \\cdot \\max(|w|)} + \\frac{1}{2}$$\n",
        "where $2 \\cdot \\max(|w|)$ is the **adaptive scale**.\n",
        "\n",
        "Then, we quantize the transformed weights:\n",
        "$$\\hat{w} = \\text{quantizer}_{\\text{n-bit}}(\\tilde{w})$$\n",
        "After quantization, a reverse scaling function can be applied on $\\hat{w}$ to recover the original scale:\n",
        "\n",
        "$$w_q = 2 \\cdot \\max(|w|) \\cdot \\left( \\hat{w}-\\frac{1}{2} \\right)$$\n",
        "\n",
        "Combining these three equations, the expression we will use to get the quantized weights $w_q$ is as follows:\n",
        "$$w_q = 2 \\cdot \\max(|w|) \\cdot \\left[ \\text{quantizer}_{\\text{n-bit}} \\left( \\frac{w}{2\\max(|w|)} + \\frac{1}{2} \\right) - \\frac{1}{2} \\right]$$\n",
        "\n",
        "This equation is the **deterministic quantization function**.\n",
        "\n",
        "Following the method proposed by [DoReFa-Net](https://arxiv.org/abs/1606.06160), we enable *stochastic quantization* by adding extra noise $N(n) = \\frac{\\sigma}{2^n-1}$ to the transformed weights $\\tilde{w}$, where $\\sigma \\sim \\text{Uniform}(-0.5, 0.5)$ and $n$ is the number of bits.\n",
        "Generally, including such extra noise will coax the model into exploring more of the loss surface, helping the model escape local minima and improve model generalizability.  \n",
        "\n",
        "The final **stochastic quantization function** we will use to quantize layers of local models is:\n",
        "\n",
        "$$w_q = 2 \\cdot \\max(|w|) \\cdot \\left[ \\text{quantizer}_{\\text{n-bit}} \\left( \\frac{w}{2 \\cdot \\max(|w|)} + \\frac{1}{2} + N(n) \\right) - \\frac{1}{2} \\right]$$\n",
        "\n",
        "\n",
        "<font color='red'>**PART 3.2:**</font> [10 points]\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 3.2*, implement `dorefa_g(w, nbit, adaptive_scale=None)` using the **stochastic quantization function** shown above. Again, if your implementation is correct, it should return *'Output of Quantization Matches!'*.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGIOhKnWqXXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e416f84-c5bc-4b0f-fc2f-2c86bedfe9ba"
      },
      "source": [
        "## Code Cell 3.2\n",
        "\n",
        "def quantize_model(model, nbit):\n",
        "    '''\n",
        "    Used in Code Cell 3.3 to quantize the ConvNet model\n",
        "    '''\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "            m.weight.data, m.adaptive_scale = dorefa_g(m.weight, nbit)\n",
        "            if m.bias is not None:\n",
        "                m.bias.data,_ = dorefa_g(m.bias, nbit, m.adaptive_scale)\n",
        "\n",
        "def dorefa_g(w, nbit, adaptive_scale=None):\n",
        "    '''\n",
        "    w: a floating-point weight tensor to quantize\n",
        "    nbit: the number of bits in the quantized representation\n",
        "    adaptive_scale: the maximum scale value. if None, it is set to be the\n",
        "                    absolute maximum value in w.\n",
        "    '''\n",
        "    if adaptive_scale is None:\n",
        "        adaptive_scale = 2 * torch.max(torch.abs(w))\n",
        "\n",
        "    def N(n):\n",
        "        sigma = np.random.uniform(-.5, .5)\n",
        "        return sigma / (2**n - 1)\n",
        "\n",
        "    w_tilde = w / adaptive_scale + 1/2\n",
        "\n",
        "    w_q = adaptive_scale * (quantizer(w_tilde + N(nbit), nbit) - 1/2)\n",
        "\n",
        "    # Part 3.2: Implement based on stochastic quantization function above\n",
        "\n",
        "    # remove placeholder \"return w, adaptive_scale\" line below\n",
        "    # after you implement\n",
        "    return w_q, adaptive_scale\n",
        "\n",
        "\n",
        "# Test Code\n",
        "test_data = torch.tensor([i/11 for i in range(11)])\n",
        "\n",
        "# ground truth results of 4-bit quantization\n",
        "ground_truth = torch.tensor([-0.0606, 0.0606, 0.1818, 0.3030, 0.3030, 0.4242,\n",
        "                             0.5455, 0.5455, 0.7879, 0.7879, 0.9091])\n",
        "\n",
        "# output of your quantization function\n",
        "torch.manual_seed(43)\n",
        "quantizer_output, adaptive_scale = dorefa_g(test_data, 4)\n",
        "\n",
        "print(ground_truth)\n",
        "print(quantizer_output)\n",
        "if torch.allclose(quantizer_output, ground_truth, atol=1e-04):\n",
        "    print('Output of Quantization Matches!')\n",
        "else:\n",
        "    print('Output of Quantization DOES NOT Match!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0606,  0.0606,  0.1818,  0.3030,  0.3030,  0.4242,  0.5455,  0.5455,\n",
            "         0.7879,  0.7879,  0.9091])\n",
            "tensor([0.0606, 0.1818, 0.1818, 0.3030, 0.4242, 0.5455, 0.5455, 0.6667, 0.7879,\n",
            "        0.9091, 0.9091])\n",
            "Output of Quantization DOES NOT Match!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaaBm5RcqmMx"
      },
      "source": [
        "**Reduce the Communication Overhead with Quantization**\n",
        "\n",
        "We will now explore the performance impact of quantization on federated learning. We will use the IID setting from **PART 1**. You will use the same federated learning code, but will first quantize each local model with the `quantize_model` function you wrote above before uploading to the central server (*Line 27, Code Cell 3.3*).\n",
        "\n",
        "<font color='red'>**PART 3.3:**</font> [10 points]\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "1. In *Code Cell 3.3*, run federated learning with the following two quantization settings (bit widths): `nbit=16` and `nbit=4`. Plot the accuracy of the global models over 100 rounds for the different bit widths: 32-bit (the full-precision baseline you ran previously), 16-bit, and 4-bit.  \n",
        "2. Discuss the accuracy difference between the global models across the three different bit width settings: 32-bit, 16-bit, and 4-bit. (100 words maximum)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUyOuVCpqrTI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "48f9210b-70ee-48de-9341-94e3ab1c8f95"
      },
      "source": [
        "## Code Cell 3.3\n",
        "\n",
        "# Part 3.2: Train two settings with nbit=16 and nbit=4.\n",
        "#           Compare against the floating-point performance\n",
        "#           of the final FL model trained in Part 1.3.\n",
        "nbit = 16\n",
        "\n",
        "rounds = 100\n",
        "local_epochs = 4\n",
        "num_devices = 50\n",
        "device_pct = 0.1\n",
        "data_pct = 0.1\n",
        "net = ConvNet().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "data_idxs = iid_sampler(trainset, num_devices, data_pct)\n",
        "devices = [create_device(net, i, trainset, data_idxs[i])\n",
        "           for i in range(num_devices)]\n",
        "\n",
        "## IID Federated Learning\n",
        "start_time = time.time()\n",
        "for round_num in range(rounds):\n",
        "    # Part 3.3: Implement!\n",
        "    # Hint: you can use your federated learning code from PART 1\n",
        "    pass\n",
        "\n",
        "    for device in devices:\n",
        "        device['net'].load_state_dict(w_avg)\n",
        "        device['optimizer'].zero_grad()\n",
        "        device['optimizer'].step()\n",
        "        device['scheduler'].step()\n",
        "\n",
        "    # test accuracy after aggregation\n",
        "    test(round_num, devices[0])\n",
        "\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print('Total training time: {} seconds'.format(total_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-6e7526e1c291>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdevice_pct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdata_pct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \"\"\"\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \"\"\"\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **4. Gradient Inversion Attacks to Federated Learning**\n",
        "\n",
        "In this part, you will explore gradient inversion attacks which may break privacy in federated learning. In federated learning, each client receives the current global weights of the network and sends weights updates (gradients) based on local data. But how secure is sharing weights gradients? The [Deep Leakage](https://arxiv.org/pdf/1906.08935.pdf) paper shows it is possible to recover data given weights gradients.\n",
        "To perform the attack, Deep Leakage first randomly generates a pair of \"dummy\" inputs and labels and then performs the usual forward and backwards computation.\n",
        "After deriving the dummy gradients from the dummy data, instead of optimizing model weights as in typical training, Deep Leakage optimizes the dummy inputs and labels to minimize the distance between dummy gradients and real gradients. You may refer to the paper for more details."
      ],
      "metadata": {
        "id": "ehxZ_h81CKXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Code Cell 4.1\n",
        "dst = datasets.CIFAR100(\"./data\", download=True)\n",
        "tp = transforms.Compose([\n",
        "    transforms.Resize(32),\n",
        "    transforms.CenterCrop(32),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "tt = transforms.ToPILImage()\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "print(\"Running on %s\" % device)\n",
        "\n",
        "def label_to_onehot(target, num_classes=100):\n",
        "    target = torch.unsqueeze(target, 1)\n",
        "    onehot_target = torch.zeros(target.size(0), num_classes, device=target.device)\n",
        "    onehot_target.scatter_(1, target, 1)\n",
        "    return onehot_target\n",
        "\n",
        "def cross_entropy_for_onehot(pred, target):\n",
        "    return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), 1))\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    if hasattr(m, \"weight\"):\n",
        "        m.weight.data.uniform_(-0.5, 0.5)\n",
        "    if hasattr(m, \"bias\"):\n",
        "        m.bias.data.uniform_(-0.5, 0.5)\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        act = nn.Sigmoid\n",
        "        self.body = nn.Sequential(\n",
        "            nn.Conv2d(3, 12, kernel_size=5, padding=5//2, stride=2),\n",
        "            act(),\n",
        "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=2),\n",
        "            act(),\n",
        "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
        "            act(),\n",
        "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
        "            act(),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(768, 100)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.body(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        # print(out.size())\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "net = LeNet().to(device)\n",
        "\n",
        "net.apply(weights_init)\n",
        "criterion = cross_entropy_for_onehot\n",
        "\n",
        "######### one client #########\n",
        "img_index = 25\n",
        "gt_data = tp(dst[img_index][0]).to(device)\n",
        "gt_data = gt_data.view(1, *gt_data.size())\n",
        "gt_label = torch.Tensor([dst[img_index][1]]).long().to(device)\n",
        "gt_label = gt_label.view(1, )\n",
        "gt_onehot_label = label_to_onehot(gt_label, num_classes=100)\n",
        "\n",
        "plt.imshow(tt(gt_data[0].cpu()))\n",
        "plt.title(\"Ground truth image\")\n",
        "print(\"GT label is %d.\" % gt_label.item(), \"\\nOnehot label is %d.\" % torch.argmax(gt_onehot_label, dim=-1).item())\n",
        "\n",
        "# compute original gradient\n",
        "out = net(gt_data)\n",
        "y = criterion(out, gt_onehot_label)\n",
        "dy_dx = torch.autograd.grad(y, net.parameters())\n",
        "\n",
        "\n",
        "# share the gradients with the server\n",
        "original_dy_dx = list((_.detach().clone() for _ in dy_dx))\n",
        "\n",
        "\n",
        "def defense_method(dy_dx, defense_strategy):\n",
        "\n",
        "  if defense_strategy=='none':\n",
        "    # no defense\n",
        "    return dy_dx\n",
        "\n",
        "  elif defense_strategy=='pruning':\n",
        "    # PART 4.1: pruning\n",
        "    return ...\n",
        "\n",
        "  elif defense_strategy=='quantization':\n",
        "    # PART 4.1: quantization\n",
        "    return ...\n",
        "\n",
        "  elif defense_strategy=='noise':\n",
        "    # PART 4.1: noise injection\n",
        "    return ...\n",
        "\n",
        "\n",
        "original_dy_dx = defense_method(original_dy_dx, your_defense)\n",
        "\n",
        "######### Start attack ##########\n",
        "\n",
        "# generate dummy data and label\n",
        "dummy_data = torch.randn(gt_data.size()).to(device).requires_grad_(True)\n",
        "dummy_label = torch.randn(gt_onehot_label.size()).to(device).requires_grad_(True)\n",
        "\n",
        "plt.imshow(tt(dummy_data[0].cpu()))\n",
        "plt.title(\"Dummy data\")\n",
        "print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
        "\n",
        "optimizer = torch.optim.LBFGS([dummy_data, dummy_label] )\n",
        "\n",
        "history = []\n",
        "for iters in range(300):\n",
        "    def closure():\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred = net(dummy_data)\n",
        "        dummy_onehot_label = F.softmax(dummy_label, dim=-1)\n",
        "        dummy_loss = criterion(pred, dummy_onehot_label) # TODO: fix the gt_label to dummy_label\n",
        "        dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
        "\n",
        "        grad_diff = 0\n",
        "        grad_count = 0\n",
        "        for gx, gy in zip(dummy_dy_dx, original_dy_dx): # TODO: fix the variables here\n",
        "            grad_diff += ((gx - gy) ** 2).sum()\n",
        "            grad_count += gx.nelement()\n",
        "        # grad_diff = grad_diff / grad_count * 1000\n",
        "        grad_diff.backward()\n",
        "\n",
        "        return grad_diff\n",
        "\n",
        "    optimizer.step(closure)\n",
        "    if iters % 10 == 0:\n",
        "        current_loss = closure()\n",
        "        print(iters, \"%.4f\" % current_loss.item())\n",
        "    history.append(tt(dummy_data[0].cpu()))\n",
        "\n"
      ],
      "metadata": {
        "id": "EPkQJuvpNQJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Code Cell 4.2\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i in range(30):\n",
        "  plt.subplot(3, 10, i + 1)\n",
        "  plt.imshow(history[i * 10])\n",
        "  plt.title(\"iter=%d\" % (i * 10))\n",
        "  plt.axis('off')\n",
        "print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())"
      ],
      "metadata": {
        "id": "ViVYjdl_uYue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>**PART 4.1:**</font> [15 points]\n",
        "\n",
        "In this part, we conduct a gradient inversion attack on a ConvNet model and implement several defense strategies. You will run experiments under 4 different settings:\n",
        "1. Baseline: original Deep Leakage without any defenses (we have provided this code in *Code Cell 4.1*)\n",
        "2. Noise: defend against the attack by injecting Gaussian noise $\\mathcal{N}(0, 10^{-3})$ to the weights gradients\n",
        "3. Pruning: defend against the attack by pruning gradients: use unstructured magnitude pruning to set 20% of the gradient values to zero.\n",
        "4. Quantization: defend against the attack by performing 4-bit quantization (`nbit=4`) on the gradients with the function you implemented in **PART 3.2**.\n",
        "\n",
        "<font color='red'>**Deliverables**</font>\n",
        "\n",
        "1. Implement the three defense strategies (i.e., noise injection, pruning, and quantization) `defense_method` in *Code Cell 4.1*.\n",
        "2. Run the 4 experiments (i.e., Baseline, Noise, Pruning, and Quantization). For each experiment, you should report: (1) the final inversion result as measured by $\\|\\text{image}-\\text{recovered_image}\\|_2$ and (2) the optimization process of inversion using *Code Cell 4.2*.\n",
        "3. Compare and discuss the effectiveness of the 3 different defense strategies. (100 words maximum)\n"
      ],
      "metadata": {
        "id": "Sc0OjDXzNXqo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K0cMu4r5wvXw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}